2016-11-25 20:22:19 >>> version=v11-dropout
2016-11-25 20:22:19 >>> loading config file extract_pfiles_python/out/v09-without-frame-limiting-context40/config.json
2016-11-25 20:22:19 >>> loading numpy file extract_pfiles_python/out/v09-without-frame-limiting-context40/train.npz
2016-11-25 20:22:22 >>> loading numpy file extract_pfiles_python/out/v09-without-frame-limiting-context40/validate.npz
2016-11-25 20:22:23 >>> Using fuzzy_newbob as schedulung method.
2016-11-25 20:22:23 >>> Training network with 21452 trainable out of 21452 total params.
2016-11-25 20:22:23 >>> Using adadelta with learning_rate=1.000000
2016-11-25 20:22:23 >>> Compiling theano functions...
2016-11-25 20:22:28 >>> Starting training...
2016-11-25 20:23:18 >>>   training loss:	0.666861
2016-11-25 20:23:18 >>> Saving network params to trainNN/out/v11-dropout/epoch-000.pkl
2016-11-25 20:23:20 >>> epoch: 0 validation error:		0.399907
2016-11-25 20:24:12 >>>   training loss:	0.660689
2016-11-25 20:24:12 >>> Saving network params to trainNN/out/v11-dropout/epoch-001.pkl
2016-11-25 20:24:13 >>> epoch: 1 validation error:		0.391804
2016-11-25 20:25:11 >>>   training loss:	0.658206
2016-11-25 20:25:11 >>> Saving network params to trainNN/out/v11-dropout/epoch-002.pkl
2016-11-25 20:25:12 >>> epoch: 2 validation error:		0.388778
2016-11-25 20:26:14 >>>   training loss:	0.657050
2016-11-25 20:26:14 >>> Saving network params to trainNN/out/v11-dropout/epoch-003.pkl
2016-11-25 20:26:16 >>> epoch: 3 validation error:		0.386655
2016-11-25 20:27:10 >>>   training loss:	0.656042
2016-11-25 20:27:10 >>> Saving network params to trainNN/out/v11-dropout/epoch-004.pkl
2016-11-25 20:27:11 >>> epoch: 4 validation error:		0.384607
2016-11-25 20:28:02 >>>   training loss:	0.655345
2016-11-25 20:28:02 >>> Saving network params to trainNN/out/v11-dropout/epoch-005.pkl
2016-11-25 20:28:03 >>> epoch: 5 validation error:		0.383446
2016-11-25 20:29:00 >>>   training loss:	0.654699
2016-11-25 20:29:00 >>> Saving network params to trainNN/out/v11-dropout/epoch-006.pkl
2016-11-25 20:29:02 >>> epoch: 6 validation error:		0.382252
2016-11-25 20:29:54 >>>   training loss:	0.654052
2016-11-25 20:29:54 >>> Saving network params to trainNN/out/v11-dropout/epoch-007.pkl
2016-11-25 20:29:55 >>> epoch: 7 validation error:		0.380989
2016-11-25 20:30:57 >>>   training loss:	0.653395
2016-11-25 20:30:57 >>> Saving network params to trainNN/out/v11-dropout/epoch-008.pkl
2016-11-25 20:30:58 >>> epoch: 8 validation error:		0.380068
2016-11-25 20:31:50 >>>   training loss:	0.652874
2016-11-25 20:31:50 >>> Saving network params to trainNN/out/v11-dropout/epoch-009.pkl
2016-11-25 20:31:51 >>> epoch: 9 validation error:		0.380780
2016-11-25 20:31:51 >>> Loading old params from trainNN/out/v11-dropout/epoch-008.pkl
2016-11-25 20:31:51 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.500000
2016-11-25 20:31:51 >>> Re-compiling train function...
2016-11-25 20:32:46 >>>   training loss:	0.652612
2016-11-25 20:32:46 >>> Saving network params to trainNN/out/v11-dropout/epoch-010.pkl
2016-11-25 20:32:47 >>> epoch: 10 validation error:		0.378186
2016-11-25 20:33:42 >>>   training loss:	0.652270
2016-11-25 20:33:42 >>> Saving network params to trainNN/out/v11-dropout/epoch-011.pkl
2016-11-25 20:33:43 >>> epoch: 11 validation error:		0.378145
2016-11-25 20:34:38 >>>   training loss:	0.652093
2016-11-25 20:34:38 >>> Saving network params to trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:34:40 >>> epoch: 12 validation error:		0.376963
2016-11-25 20:35:36 >>>   training loss:	0.651754
2016-11-25 20:35:36 >>> Saving network params to trainNN/out/v11-dropout/epoch-013.pkl
2016-11-25 20:35:37 >>> epoch: 13 validation error:		0.377196
2016-11-25 20:35:37 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:35:38 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.250000
2016-11-25 20:35:38 >>> Re-compiling train function...
2016-11-25 20:36:36 >>>   training loss:	0.651764
2016-11-25 20:36:36 >>> Saving network params to trainNN/out/v11-dropout/epoch-014.pkl
2016-11-25 20:36:38 >>> epoch: 14 validation error:		0.377277
2016-11-25 20:36:38 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:36:38 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.125000
2016-11-25 20:36:38 >>> Re-compiling train function...
2016-11-25 20:37:50 >>>   training loss:	0.651781
2016-11-25 20:37:50 >>> Saving network params to trainNN/out/v11-dropout/epoch-015.pkl
2016-11-25 20:37:51 >>> epoch: 15 validation error:		0.377315
2016-11-25 20:37:51 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:37:51 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.062500
2016-11-25 20:37:51 >>> Re-compiling train function...
2016-11-25 20:38:43 >>>   training loss:	0.651626
2016-11-25 20:38:43 >>> Saving network params to trainNN/out/v11-dropout/epoch-016.pkl
2016-11-25 20:38:45 >>> epoch: 16 validation error:		0.377335
2016-11-25 20:38:45 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:38:45 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.031250
2016-11-25 20:38:45 >>> Re-compiling train function...
2016-11-25 20:39:38 >>>   training loss:	0.651684
2016-11-25 20:39:38 >>> Saving network params to trainNN/out/v11-dropout/epoch-017.pkl
2016-11-25 20:39:39 >>> epoch: 17 validation error:		0.377364
2016-11-25 20:39:39 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:39:39 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.015625
2016-11-25 20:39:39 >>> Re-compiling train function...
2016-11-25 20:40:43 >>>   training loss:	0.651788
2016-11-25 20:40:43 >>> Saving network params to trainNN/out/v11-dropout/epoch-018.pkl
2016-11-25 20:40:44 >>> epoch: 18 validation error:		0.377472
2016-11-25 20:40:44 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:40:44 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.007812
2016-11-25 20:40:44 >>> Re-compiling train function...
2016-11-25 20:41:38 >>>   training loss:	0.651754
2016-11-25 20:41:38 >>> Saving network params to trainNN/out/v11-dropout/epoch-019.pkl
2016-11-25 20:41:40 >>> epoch: 19 validation error:		0.377448
2016-11-25 20:41:40 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:41:40 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.003906
2016-11-25 20:41:40 >>> Re-compiling train function...
2016-11-25 20:42:29 >>>   training loss:	0.651786
2016-11-25 20:42:29 >>> Saving network params to trainNN/out/v11-dropout/epoch-020.pkl
2016-11-25 20:42:31 >>> epoch: 20 validation error:		0.377274
2016-11-25 20:42:31 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:42:31 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.001953
2016-11-25 20:42:31 >>> Re-compiling train function...
2016-11-25 20:43:26 >>>   training loss:	0.651918
2016-11-25 20:43:26 >>> Saving network params to trainNN/out/v11-dropout/epoch-021.pkl
2016-11-25 20:43:27 >>> epoch: 21 validation error:		0.377071
2016-11-25 20:43:27 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:43:27 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000977
2016-11-25 20:43:27 >>> Re-compiling train function...
2016-11-25 20:44:17 >>>   training loss:	0.651806
2016-11-25 20:44:17 >>> Saving network params to trainNN/out/v11-dropout/epoch-022.pkl
2016-11-25 20:44:18 >>> epoch: 22 validation error:		0.377109
2016-11-25 20:44:18 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:44:18 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000488
2016-11-25 20:44:18 >>> Re-compiling train function...
2016-11-25 20:45:11 >>>   training loss:	0.651866
2016-11-25 20:45:11 >>> Saving network params to trainNN/out/v11-dropout/epoch-023.pkl
2016-11-25 20:45:13 >>> epoch: 23 validation error:		0.377082
2016-11-25 20:45:13 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:45:13 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000244
2016-11-25 20:45:13 >>> Re-compiling train function...
2016-11-25 20:46:08 >>>   training loss:	0.651858
2016-11-25 20:46:08 >>> Saving network params to trainNN/out/v11-dropout/epoch-024.pkl
2016-11-25 20:46:09 >>> epoch: 24 validation error:		0.377039
2016-11-25 20:46:09 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:46:09 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000122
2016-11-25 20:46:09 >>> Re-compiling train function...
2016-11-25 20:46:59 >>>   training loss:	0.652021
2016-11-25 20:46:59 >>> Saving network params to trainNN/out/v11-dropout/epoch-025.pkl
2016-11-25 20:47:00 >>> epoch: 25 validation error:		0.376978
2016-11-25 20:47:00 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:47:00 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000061
2016-11-25 20:47:00 >>> Re-compiling train function...
2016-11-25 20:47:50 >>>   training loss:	0.651875
2016-11-25 20:47:50 >>> Saving network params to trainNN/out/v11-dropout/epoch-026.pkl
2016-11-25 20:47:51 >>> epoch: 26 validation error:		0.377007
2016-11-25 20:47:51 >>> Loading old params from trainNN/out/v11-dropout/epoch-012.pkl
2016-11-25 20:47:51 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000031
2016-11-25 20:47:51 >>> Re-compiling train function...
2016-11-25 20:48:46 >>>   training loss:	0.651907
2016-11-25 20:48:46 >>> Saving network params to trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:48:48 >>> epoch: 27 validation error:		0.376946
2016-11-25 20:49:46 >>>   training loss:	0.651840
2016-11-25 20:49:46 >>> Saving network params to trainNN/out/v11-dropout/epoch-028.pkl
2016-11-25 20:49:47 >>> epoch: 28 validation error:		0.376992
2016-11-25 20:49:47 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:49:47 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000015
2016-11-25 20:49:47 >>> Re-compiling train function...
2016-11-25 20:50:43 >>>   training loss:	0.651952
2016-11-25 20:50:43 >>> Saving network params to trainNN/out/v11-dropout/epoch-029.pkl
2016-11-25 20:50:44 >>> epoch: 29 validation error:		0.376969
2016-11-25 20:50:44 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:50:44 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000008
2016-11-25 20:50:44 >>> Re-compiling train function...
2016-11-25 20:51:42 >>>   training loss:	0.651990
2016-11-25 20:51:42 >>> Saving network params to trainNN/out/v11-dropout/epoch-030.pkl
2016-11-25 20:51:43 >>> epoch: 30 validation error:		0.376984
2016-11-25 20:51:43 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:51:43 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000004
2016-11-25 20:51:43 >>> Re-compiling train function...
2016-11-25 20:52:40 >>>   training loss:	0.651920
2016-11-25 20:52:40 >>> Saving network params to trainNN/out/v11-dropout/epoch-031.pkl
2016-11-25 20:52:43 >>> epoch: 31 validation error:		0.376978
2016-11-25 20:52:43 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:52:43 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000002
2016-11-25 20:52:43 >>> Re-compiling train function...
2016-11-25 20:53:34 >>>   training loss:	0.651933
2016-11-25 20:53:34 >>> Saving network params to trainNN/out/v11-dropout/epoch-032.pkl
2016-11-25 20:53:35 >>> epoch: 32 validation error:		0.376998
2016-11-25 20:53:35 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:53:35 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000001
2016-11-25 20:53:35 >>> Re-compiling train function...
2016-11-25 20:54:33 >>>   training loss:	0.651992
2016-11-25 20:54:33 >>> Saving network params to trainNN/out/v11-dropout/epoch-033.pkl
2016-11-25 20:54:35 >>> epoch: 33 validation error:		0.376969
2016-11-25 20:54:35 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:54:35 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000000
2016-11-25 20:54:35 >>> Re-compiling train function...
2016-11-25 20:55:38 >>>   training loss:	0.651959
2016-11-25 20:55:38 >>> Saving network params to trainNN/out/v11-dropout/epoch-034.pkl
2016-11-25 20:55:39 >>> epoch: 34 validation error:		0.376975
2016-11-25 20:55:39 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:55:39 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000000
2016-11-25 20:55:39 >>> Re-compiling train function...
2016-11-25 20:56:39 >>>   training loss:	0.651877
2016-11-25 20:56:39 >>> Saving network params to trainNN/out/v11-dropout/epoch-035.pkl
2016-11-25 20:56:41 >>> epoch: 35 validation error:		0.376984
2016-11-25 20:56:41 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:56:41 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000000
2016-11-25 20:56:41 >>> Re-compiling train function...
2016-11-25 20:57:31 >>> received exit signal, waiting for epoch to finish...
2016-11-25 20:57:38 >>>   training loss:	0.651898
2016-11-25 20:57:38 >>> Saving network params to trainNN/out/v11-dropout/epoch-036.pkl
2016-11-25 20:57:39 >>> epoch: 36 validation error:		0.376949
2016-11-25 20:57:39 >>> Loading old params from trainNN/out/v11-dropout/epoch-027.pkl
2016-11-25 20:57:39 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000000
2016-11-25 20:57:39 >>> Re-compiling train function...
2016-11-25 20:57:40 >>> Wrote output to trainNN/out/v11-dropout/config.json
