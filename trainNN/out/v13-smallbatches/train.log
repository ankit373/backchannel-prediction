2016-11-25 22:33:44 >>> version=v13-smallbatches
2016-11-25 22:33:44 >>> loading config file extract_pfiles_python/out/v09-without-frame-limiting-context40/config.json
2016-11-25 22:33:44 >>> loading numpy file extract_pfiles_python/out/v09-without-frame-limiting-context40/train.npz
2016-11-25 22:33:47 >>> loading numpy file extract_pfiles_python/out/v09-without-frame-limiting-context40/validate.npz
2016-11-25 22:33:48 >>> Using fuzzy_newbob as schedulung method.
2016-11-25 22:33:48 >>> Training network with 21452 trainable out of 21452 total params.
2016-11-25 22:33:48 >>> Using adadelta with learning_rate=1.000000
2016-11-25 22:33:48 >>> Compiling theano functions...
2016-11-25 22:33:48 >>> Starting training...
2016-11-25 22:35:01 >>>   training loss:	0.649996
2016-11-25 22:35:01 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-000.pkl
2016-11-25 22:35:04 >>> epoch: 0 validation error:		0.369312
2016-11-25 22:36:20 >>>   training loss:	0.637005
2016-11-25 22:36:20 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-001.pkl
2016-11-25 22:36:23 >>> epoch: 1 validation error:		0.372474
2016-11-25 22:36:23 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-000.pkl
2016-11-25 22:36:23 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.500000
2016-11-25 22:36:23 >>> Re-compiling train function...
2016-11-25 22:37:38 >>>   training loss:	0.636056
2016-11-25 22:37:38 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-002.pkl
2016-11-25 22:37:41 >>> epoch: 2 validation error:		0.361730
2016-11-25 22:38:55 >>>   training loss:	0.632235
2016-11-25 22:38:55 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-003.pkl
2016-11-25 22:38:58 >>> epoch: 3 validation error:		0.358396
2016-11-25 22:40:13 >>>   training loss:	0.629548
2016-11-25 22:40:13 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-004.pkl
2016-11-25 22:40:16 >>> epoch: 4 validation error:		0.357624
2016-11-25 22:41:52 >>>   training loss:	0.627661
2016-11-25 22:41:52 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-005.pkl
2016-11-25 22:41:58 >>> epoch: 5 validation error:		0.356733
2016-11-25 22:45:03 >>>   training loss:	0.626192
2016-11-25 22:45:03 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-006.pkl
2016-11-25 22:45:09 >>> epoch: 6 validation error:		0.358007
2016-11-25 22:45:09 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-005.pkl
2016-11-25 22:45:09 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.250000
2016-11-25 22:45:09 >>> Re-compiling train function...
2016-11-25 22:48:29 >>>   training loss:	0.624531
2016-11-25 22:48:29 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-007.pkl
2016-11-25 22:48:37 >>> epoch: 7 validation error:		0.355510
2016-11-25 22:51:45 >>>   training loss:	0.623792
2016-11-25 22:51:45 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-008.pkl
2016-11-25 22:51:51 >>> epoch: 8 validation error:		0.355054
2016-11-25 22:55:51 >>>   training loss:	0.623135
2016-11-25 22:55:51 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-009.pkl
2016-11-25 22:55:55 >>> epoch: 9 validation error:		0.355028
2016-11-25 22:57:06 >>>   training loss:	0.622562
2016-11-25 22:57:06 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-010.pkl
2016-11-25 22:57:09 >>> epoch: 10 validation error:		0.354346
2016-11-25 22:58:20 >>>   training loss:	0.622068
2016-11-25 22:58:20 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-011.pkl
2016-11-25 22:58:23 >>> epoch: 11 validation error:		0.354555
2016-11-25 22:58:23 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-010.pkl
2016-11-25 22:58:23 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.125000
2016-11-25 22:58:23 >>> Re-compiling train function...
2016-11-25 23:00:15 >>>   training loss:	0.620866
2016-11-25 23:00:15 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-012.pkl
2016-11-25 23:00:20 >>> epoch: 12 validation error:		0.353138
2016-11-25 23:03:52 >>>   training loss:	0.620517
2016-11-25 23:03:52 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-013.pkl
2016-11-25 23:03:57 >>> epoch: 13 validation error:		0.352023
2016-11-25 23:07:25 >>>   training loss:	0.620236
2016-11-25 23:07:25 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-014.pkl
2016-11-25 23:07:30 >>> epoch: 14 validation error:		0.353399
2016-11-25 23:07:30 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-013.pkl
2016-11-25 23:07:30 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.062500
2016-11-25 23:07:30 >>> Re-compiling train function...
2016-11-25 23:10:29 >>>   training loss:	0.619543
2016-11-25 23:10:29 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-015.pkl
2016-11-25 23:10:36 >>> epoch: 15 validation error:		0.352557
2016-11-25 23:10:36 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-013.pkl
2016-11-25 23:10:36 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.031250
2016-11-25 23:10:36 >>> Re-compiling train function...
2016-11-25 23:14:06 >>>   training loss:	0.619214
2016-11-25 23:14:06 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-016.pkl
2016-11-25 23:14:11 >>> epoch: 16 validation error:		0.352374
2016-11-25 23:14:11 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-013.pkl
2016-11-25 23:14:11 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.015625
2016-11-25 23:14:11 >>> Re-compiling train function...
2016-11-25 23:17:37 >>>   training loss:	0.619088
2016-11-25 23:17:37 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-017.pkl
2016-11-25 23:17:42 >>> epoch: 17 validation error:		0.351930
2016-11-25 23:20:46 >>>   training loss:	0.618941
2016-11-25 23:20:46 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-018.pkl
2016-11-25 23:20:49 >>> epoch: 18 validation error:		0.351747
2016-11-25 23:21:59 >>>   training loss:	0.618881
2016-11-25 23:21:59 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-019.pkl
2016-11-25 23:22:02 >>> epoch: 19 validation error:		0.352113
2016-11-25 23:22:02 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-018.pkl
2016-11-25 23:22:02 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.007812
2016-11-25 23:22:02 >>> Re-compiling train function...
2016-11-25 23:23:14 >>>   training loss:	0.618778
2016-11-25 23:23:14 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-020.pkl
2016-11-25 23:23:17 >>> epoch: 20 validation error:		0.352275
2016-11-25 23:23:17 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-018.pkl
2016-11-25 23:23:17 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.003906
2016-11-25 23:23:17 >>> Re-compiling train function...
2016-11-25 23:24:29 >>>   training loss:	0.618738
2016-11-25 23:24:29 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-021.pkl
2016-11-25 23:24:32 >>> epoch: 21 validation error:		0.352203
2016-11-25 23:24:32 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-018.pkl
2016-11-25 23:24:32 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.001953
2016-11-25 23:24:32 >>> Re-compiling train function...
2016-11-25 23:25:56 >>>   training loss:	0.618718
2016-11-25 23:25:56 >>> Saving network params to trainNN/out/v13-smallbatches/epoch-022.pkl
2016-11-25 23:25:59 >>> epoch: 22 validation error:		0.352121
2016-11-25 23:25:59 >>> Loading old params from trainNN/out/v13-smallbatches/epoch-018.pkl
2016-11-25 23:25:59 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.000977
2016-11-25 23:25:59 >>> Re-compiling train function...
