2016-11-26 00:42:31 >>> version=v15-adam-1-g5307ea4-dirty
2016-11-26 00:42:31 >>> loading config file extract_pfiles_python/out/v09-without-frame-limiting-context40/config.json
2016-11-26 00:42:31 >>> loading numpy file extract_pfiles_python/out/v09-without-frame-limiting-context40/train.npz
2016-11-26 00:42:34 >>> loading numpy file extract_pfiles_python/out/v09-without-frame-limiting-context40/validate.npz
2016-11-26 00:42:34 >>> Using fuzzy_newbob as schedulung method.
2016-11-26 00:42:35 >>> Training network with 21452 trainable out of 21452 total params.
2016-11-26 00:42:35 >>> Using adam with learning_rate=0.001000
2016-11-26 00:42:35 >>> Compiling theano functions...
2016-11-26 00:42:35 >>> Starting training...
2016-11-26 00:42:57 >>>   training loss:	0.651453
2016-11-26 00:42:57 >>> Saving network params to trainNN/out/v15-adam-1-g5307ea4-dirty/epoch-000.pkl
2016-11-26 00:42:58 >>> epoch: 0 validation error:		0.371611
2016-11-26 00:43:20 >>>   training loss:	0.639178
2016-11-26 00:43:20 >>> Saving network params to trainNN/out/v15-adam-1-g5307ea4-dirty/epoch-001.pkl
2016-11-26 00:43:21 >>> epoch: 1 validation error:		0.366824
2016-11-26 00:43:43 >>>   training loss:	0.634209
2016-11-26 00:43:43 >>> Saving network params to trainNN/out/v15-adam-1-g5307ea4-dirty/epoch-002.pkl
2016-11-26 00:43:44 >>> epoch: 2 validation error:		0.360807
2016-11-26 00:43:55 >>> received exit signal, waiting for epoch to finish...
2016-11-26 00:44:06 >>>   training loss:	0.631032
2016-11-26 00:44:06 >>> Saving network params to trainNN/out/v15-adam-1-g5307ea4-dirty/epoch-003.pkl
2016-11-26 00:44:07 >>> epoch: 3 validation error:		0.358065
2016-11-26 00:44:07 >>> Wrote output to trainNN/out/v15-adam-1-g5307ea4-dirty/config.json
