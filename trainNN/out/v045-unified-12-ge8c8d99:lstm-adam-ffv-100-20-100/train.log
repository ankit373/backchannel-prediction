2017-01-26 13:54:12,701 DEBUG    version=v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100
2017-01-26 13:54:12,716 INFO     Open DBase(data/db/all240302-spk.dat, data/db/all240302-spk.idx, mode='r')
2017-01-26 13:54:26,863 DEBUG    loading cached extracted data from data/cache/extract-17095dffdd75068299ccb5dd895af8ecaa0fbe1575b09b5b1ad4e4febf4d84ae.pickle
2017-01-26 13:54:28,035 DEBUG    set input dim to 9
2017-01-26 13:54:28,035 DEBUG    input dim = 9
2017-01-26 13:54:28,193 DEBUG    shuffling batches
2017-01-26 13:55:51,545 DEBUG    shuffling done
2017-01-26 13:55:51,546 DEBUG    loading data into ram
2017-01-26 13:55:51,674 DEBUG    loading data took 0.128s (cpu: 0.128s)
2017-01-26 13:55:52,234 DEBUG    set input dim to 9
2017-01-26 13:55:52,235 DEBUG    input dim = 9
2017-01-26 13:55:52,521 DEBUG    shuffling batches
2017-01-26 13:56:00,684 DEBUG    shuffling done
2017-01-26 13:56:00,684 DEBUG    loading data into ram
2017-01-26 13:56:00,697 DEBUG    loading data took 0.013s (cpu: 0.013s)
2017-01-26 13:56:01,069 INFO     Training network with 102942 trainable out of 103382 total params.
2017-01-26 13:56:02,656 DEBUG    Using adam with learning_rate=0.001000
2017-01-26 13:57:02,087 DEBUG    Starting training...
2017-01-26 14:39:12,096 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-000.pkl
2017-01-26 14:40:00,245 INFO     epoch: 0 took 2578.157s (0.044s in batching)
training loss:	0.601387
validation loss:	0.583463
validation error:	0.311653
2017-01-26 14:40:00,248 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 15:22:05,474 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-001.pkl
2017-01-26 15:22:53,425 INFO     epoch: 1 took 2573.180s (0.046s in batching)
training loss:	0.563575
validation loss:	0.578388
validation error:	0.304045
2017-01-26 15:22:53,428 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 16:04:52,431 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-002.pkl
2017-01-26 16:05:40,393 INFO     epoch: 2 took 2566.968s (0.046s in batching)
training loss:	0.536777
validation loss:	0.591613
validation error:	0.308610
2017-01-26 16:05:40,396 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 16:47:39,948 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-003.pkl
2017-01-26 16:48:28,007 INFO     epoch: 3 took 2567.614s (0.047s in batching)
training loss:	0.503214
validation loss:	0.622682
validation error:	0.315197
2017-01-26 16:48:28,010 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 17:30:27,770 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-004.pkl
2017-01-26 17:31:15,795 INFO     epoch: 4 took 2567.788s (0.047s in batching)
training loss:	0.466407
validation loss:	0.674250
validation error:	0.322206
2017-01-26 17:31:15,799 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 18:13:12,961 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-005.pkl
2017-01-26 18:14:00,879 INFO     epoch: 5 took 2565.084s (0.047s in batching)
training loss:	0.431811
validation loss:	0.710509
validation error:	0.329294
2017-01-26 18:14:00,883 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 18:56:00,221 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-006.pkl
2017-01-26 18:56:48,107 INFO     epoch: 6 took 2567.227s (0.048s in batching)
training loss:	0.400927
validation loss:	0.762682
validation error:	0.334701
2017-01-26 18:56:48,110 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 19:38:46,804 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-007.pkl
2017-01-26 19:39:34,637 INFO     epoch: 7 took 2566.530s (0.047s in batching)
training loss:	0.374603
validation loss:	0.801173
validation error:	0.336332
2017-01-26 19:39:34,640 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 20:21:30,206 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-008.pkl
2017-01-26 20:22:18,080 INFO     epoch: 8 took 2563.443s (0.047s in batching)
training loss:	0.351692
validation loss:	0.833230
validation error:	0.343742
2017-01-26 20:22:18,083 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 21:04:15,250 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-009.pkl
2017-01-26 21:05:03,264 INFO     epoch: 9 took 2565.185s (0.048s in batching)
training loss:	0.331792
validation loss:	0.877348
validation error:	0.342880
2017-01-26 21:05:03,269 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 21:47:01,320 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-010.pkl
2017-01-26 21:47:49,137 INFO     epoch: 10 took 2565.873s (0.047s in batching)
training loss:	0.314980
validation loss:	0.922351
validation error:	0.345933
2017-01-26 21:47:49,142 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 22:29:45,968 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-011.pkl
2017-01-26 22:30:33,806 INFO     epoch: 11 took 2564.669s (0.047s in batching)
training loss:	0.301192
validation loss:	0.958689
validation error:	0.350097
2017-01-26 22:30:33,810 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 23:12:33,046 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-012.pkl
2017-01-26 23:13:20,905 INFO     epoch: 12 took 2567.099s (0.047s in batching)
training loss:	0.288695
validation loss:	0.982648
validation error:	0.353046
2017-01-26 23:13:20,908 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-26 23:55:44,277 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-013.pkl
2017-01-26 23:56:48,729 INFO     epoch: 13 took 2607.825s (0.046s in batching)
training loss:	0.277791
validation loss:	1.018718
validation error:	0.358652
2017-01-26 23:56:48,834 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
2017-01-27 00:32:02,180 INFO     received exit signal, waiting for epoch to finish...
2017-01-27 01:08:21,006 INFO     Saving network params to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/epoch-014.pkl
2017-01-27 01:10:14,684 INFO     epoch: 14 took 4405.954s (0.048s in batching)
training loss:	0.267937
validation loss:	1.044227
validation error:	0.354112
2017-01-27 01:10:14,688 INFO     Wrote output to trainNN/out/v045-unified-12-ge8c8d99:lstm-adam-ffv-100-20-100/config.json
