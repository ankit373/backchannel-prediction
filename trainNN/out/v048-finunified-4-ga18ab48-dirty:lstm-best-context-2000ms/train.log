2017-02-05 05:10:58,782 DEBUG    version=v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms
2017-02-05 05:10:58,783 INFO     Open DBase(data/db/all240302-spk.dat, data/db/all240302-spk.idx, mode='r')
2017-02-05 05:11:13,926 DEBUG    extracting and saving data to data/cache/extract-cde3a72236f87232569c617e4662801c795cbf20227d160fe880eab79dd4ac41.pickle
2017-02-05 05:12:44,583 DEBUG    set input dim to 14
2017-02-05 05:12:44,583 DEBUG    input dim = 14
2017-02-05 05:12:44,598 DEBUG    shuffling batches
2017-02-05 05:12:51,151 DEBUG    shuffling done
2017-02-05 05:12:51,151 DEBUG    loading data into ram
2017-02-05 05:12:51,279 DEBUG    loading data took 0.127s (cpu: 0.127s)
2017-02-05 05:12:51,619 DEBUG    set input dim to 14
2017-02-05 05:12:51,620 DEBUG    input dim = 14
2017-02-05 05:12:51,658 DEBUG    shuffling batches
2017-02-05 05:12:52,339 DEBUG    shuffling done
2017-02-05 05:12:52,339 DEBUG    loading data into ram
2017-02-05 05:12:52,353 DEBUG    loading data took 0.014s (cpu: 0.014s)
2017-02-05 05:12:52,503 DEBUG    Applying L2 regularization with 0.000100
2017-02-05 05:12:52,646 INFO     Training network with 39027 trainable out of 39237 total params.
2017-02-05 05:12:53,593 DEBUG    Using adam with learning_rate=0.001000
2017-02-05 05:13:34,402 DEBUG    Starting training...
2017-02-05 05:15:13,292 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-000.pkl
2017-02-05 05:15:15,483 INFO     epoch: 0 took 101.081s (0.001s in batching)
training loss:	0.610932
validation loss:	0.565385
validation error:	0.292300
2017-02-05 05:15:15,486 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:16:54,016 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-001.pkl
2017-02-05 05:16:56,221 INFO     epoch: 1 took 100.738s (0.001s in batching)
training loss:	0.577938
validation loss:	0.556246
validation error:	0.281900
2017-02-05 05:16:56,224 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:18:34,945 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-002.pkl
2017-02-05 05:18:37,113 INFO     epoch: 2 took 100.892s (0.001s in batching)
training loss:	0.568764
validation loss:	0.555766
validation error:	0.280400
2017-02-05 05:18:37,116 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:20:15,738 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-003.pkl
2017-02-05 05:20:17,934 INFO     epoch: 3 took 100.821s (0.001s in batching)
training loss:	0.561883
validation loss:	0.544148
validation error:	0.271700
2017-02-05 05:20:17,936 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:21:56,648 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-004.pkl
2017-02-05 05:21:58,772 INFO     epoch: 4 took 100.838s (0.001s in batching)
training loss:	0.556561
validation loss:	0.539252
validation error:	0.268600
2017-02-05 05:21:58,775 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:23:37,453 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-005.pkl
2017-02-05 05:23:39,658 INFO     epoch: 5 took 100.886s (0.001s in batching)
training loss:	0.551969
validation loss:	0.540669
validation error:	0.271700
2017-02-05 05:23:39,661 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:25:18,266 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-006.pkl
2017-02-05 05:25:20,425 INFO     epoch: 6 took 100.767s (0.001s in batching)
training loss:	0.549288
validation loss:	0.534570
validation error:	0.264900
2017-02-05 05:25:20,428 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:26:59,014 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-007.pkl
2017-02-05 05:27:01,222 INFO     epoch: 7 took 100.797s (0.001s in batching)
training loss:	0.545039
validation loss:	0.528530
validation error:	0.262400
2017-02-05 05:27:01,225 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:28:39,693 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-008.pkl
2017-02-05 05:28:41,863 INFO     epoch: 8 took 100.641s (0.001s in batching)
training loss:	0.543223
validation loss:	0.533641
validation error:	0.262400
2017-02-05 05:28:41,866 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:30:20,126 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-009.pkl
2017-02-05 05:30:22,301 INFO     epoch: 9 took 100.438s (0.001s in batching)
training loss:	0.539467
validation loss:	0.526950
validation error:	0.258100
2017-02-05 05:30:22,304 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:32:00,362 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-010.pkl
2017-02-05 05:32:02,559 INFO     epoch: 10 took 100.258s (0.001s in batching)
training loss:	0.536632
validation loss:	0.525455
validation error:	0.256200
2017-02-05 05:32:02,562 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:33:40,686 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-011.pkl
2017-02-05 05:33:42,829 INFO     epoch: 11 took 100.270s (0.001s in batching)
training loss:	0.534263
validation loss:	0.522809
validation error:	0.255700
2017-02-05 05:33:42,832 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:35:20,817 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-012.pkl
2017-02-05 05:35:22,962 INFO     epoch: 12 took 100.133s (0.001s in batching)
training loss:	0.532740
validation loss:	0.519997
validation error:	0.254900
2017-02-05 05:35:22,965 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:37:00,782 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-013.pkl
2017-02-05 05:37:02,936 INFO     epoch: 13 took 99.974s (0.001s in batching)
training loss:	0.530617
validation loss:	0.520670
validation error:	0.255700
2017-02-05 05:37:02,939 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:38:40,732 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-014.pkl
2017-02-05 05:38:42,890 INFO     epoch: 14 took 99.954s (0.001s in batching)
training loss:	0.529632
validation loss:	0.515767
validation error:	0.251200
2017-02-05 05:38:42,893 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:40:20,864 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-015.pkl
2017-02-05 05:40:23,031 INFO     epoch: 15 took 100.141s (0.001s in batching)
training loss:	0.527501
validation loss:	0.516413
validation error:	0.254300
2017-02-05 05:40:23,036 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:42:01,364 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-016.pkl
2017-02-05 05:42:03,518 INFO     epoch: 16 took 100.486s (0.001s in batching)
training loss:	0.526418
validation loss:	0.515346
validation error:	0.254100
2017-02-05 05:42:03,521 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:43:41,452 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-017.pkl
2017-02-05 05:43:43,608 INFO     epoch: 17 took 100.090s (0.001s in batching)
training loss:	0.524362
validation loss:	0.514189
validation error:	0.244600
2017-02-05 05:43:43,611 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:45:21,641 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-018.pkl
2017-02-05 05:45:23,851 INFO     epoch: 18 took 100.243s (0.001s in batching)
training loss:	0.524125
validation loss:	0.513427
validation error:	0.248100
2017-02-05 05:45:23,854 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:47:02,000 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-019.pkl
2017-02-05 05:47:04,213 INFO     epoch: 19 took 100.362s (0.001s in batching)
training loss:	0.522430
validation loss:	0.516031
validation error:	0.250000
2017-02-05 05:47:04,216 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:48:42,312 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-020.pkl
2017-02-05 05:48:44,409 INFO     epoch: 20 took 100.196s (0.001s in batching)
training loss:	0.521772
validation loss:	0.511693
validation error:	0.245700
2017-02-05 05:48:44,412 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:50:22,474 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-021.pkl
2017-02-05 05:50:24,641 INFO     epoch: 21 took 100.232s (0.001s in batching)
training loss:	0.520698
validation loss:	0.513671
validation error:	0.249000
2017-02-05 05:50:24,644 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:52:03,664 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-022.pkl
2017-02-05 05:52:05,865 INFO     epoch: 22 took 101.224s (0.001s in batching)
training loss:	0.519827
validation loss:	0.509394
validation error:	0.247500
2017-02-05 05:52:05,868 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:53:45,136 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-023.pkl
2017-02-05 05:53:47,320 INFO     epoch: 23 took 101.456s (0.001s in batching)
training loss:	0.518706
validation loss:	0.507947
validation error:	0.248600
2017-02-05 05:53:47,324 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:55:26,581 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-024.pkl
2017-02-05 05:55:28,784 INFO     epoch: 24 took 101.464s (0.001s in batching)
training loss:	0.517960
validation loss:	0.510014
validation error:	0.247700
2017-02-05 05:55:28,788 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:57:08,266 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-025.pkl
2017-02-05 05:57:10,518 INFO     epoch: 25 took 101.734s (0.001s in batching)
training loss:	0.516943
validation loss:	0.511819
validation error:	0.250600
2017-02-05 05:57:10,523 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 05:58:49,648 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-026.pkl
2017-02-05 05:58:51,855 INFO     epoch: 26 took 101.337s (0.001s in batching)
training loss:	0.515731
validation loss:	0.507212
validation error:	0.246800
2017-02-05 05:58:51,859 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:00:31,025 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-027.pkl
2017-02-05 06:00:33,195 INFO     epoch: 27 took 101.339s (0.001s in batching)
training loss:	0.515859
validation loss:	0.511269
validation error:	0.251300
2017-02-05 06:00:33,199 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:02:12,626 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-028.pkl
2017-02-05 06:02:14,821 INFO     epoch: 28 took 101.626s (0.001s in batching)
training loss:	0.514794
validation loss:	0.508815
validation error:	0.251800
2017-02-05 06:02:14,825 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:03:54,252 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-029.pkl
2017-02-05 06:03:56,430 INFO     epoch: 29 took 101.609s (0.001s in batching)
training loss:	0.514036
validation loss:	0.508445
validation error:	0.248600
2017-02-05 06:03:56,433 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:05:35,749 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-030.pkl
2017-02-05 06:05:37,974 INFO     epoch: 30 took 101.544s (0.001s in batching)
training loss:	0.513061
validation loss:	0.510691
validation error:	0.250400
2017-02-05 06:05:37,978 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:07:17,317 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-031.pkl
2017-02-05 06:07:19,503 INFO     epoch: 31 took 101.529s (0.001s in batching)
training loss:	0.512317
validation loss:	0.511248
validation error:	0.253000
2017-02-05 06:07:19,507 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:08:59,059 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-032.pkl
2017-02-05 06:09:01,245 INFO     epoch: 32 took 101.741s (0.001s in batching)
training loss:	0.512114
validation loss:	0.507354
validation error:	0.247400
2017-02-05 06:09:01,249 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:10:41,096 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-033.pkl
2017-02-05 06:10:43,290 INFO     epoch: 33 took 102.045s (0.001s in batching)
training loss:	0.511246
validation loss:	0.506864
validation error:	0.246900
2017-02-05 06:10:43,294 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:12:22,852 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-034.pkl
2017-02-05 06:12:25,046 INFO     epoch: 34 took 101.756s (0.001s in batching)
training loss:	0.510967
validation loss:	0.509356
validation error:	0.248600
2017-02-05 06:12:25,050 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:14:04,583 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-035.pkl
2017-02-05 06:14:06,760 INFO     epoch: 35 took 101.714s (0.001s in batching)
training loss:	0.510339
validation loss:	0.504644
validation error:	0.248100
2017-02-05 06:14:06,764 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:15:46,047 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-036.pkl
2017-02-05 06:15:48,238 INFO     epoch: 36 took 101.478s (0.001s in batching)
training loss:	0.509463
validation loss:	0.507727
validation error:	0.248600
2017-02-05 06:15:48,242 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:17:27,691 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-037.pkl
2017-02-05 06:17:29,888 INFO     epoch: 37 took 101.650s (0.001s in batching)
training loss:	0.508927
validation loss:	0.517300
validation error:	0.251500
2017-02-05 06:17:29,892 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:19:09,346 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-038.pkl
2017-02-05 06:19:11,571 INFO     epoch: 38 took 101.683s (0.001s in batching)
training loss:	0.509827
validation loss:	0.504816
validation error:	0.245100
2017-02-05 06:19:11,576 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:20:50,743 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-039.pkl
2017-02-05 06:20:52,937 INFO     epoch: 39 took 101.366s (0.001s in batching)
training loss:	0.508081
validation loss:	0.506018
validation error:	0.245300
2017-02-05 06:20:52,942 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:22:31,938 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-040.pkl
2017-02-05 06:22:34,119 INFO     epoch: 40 took 101.181s (0.001s in batching)
training loss:	0.507291
validation loss:	0.501855
validation error:	0.244300
2017-02-05 06:22:34,123 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:24:13,066 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-041.pkl
2017-02-05 06:24:15,252 INFO     epoch: 41 took 101.134s (0.001s in batching)
training loss:	0.506954
validation loss:	0.503759
validation error:	0.245200
2017-02-05 06:24:15,257 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:25:54,409 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-042.pkl
2017-02-05 06:25:56,596 INFO     epoch: 42 took 101.343s (0.001s in batching)
training loss:	0.506259
validation loss:	0.505508
validation error:	0.246000
2017-02-05 06:25:56,600 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:27:35,392 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-043.pkl
2017-02-05 06:27:37,583 INFO     epoch: 43 took 100.987s (0.001s in batching)
training loss:	0.506171
validation loss:	0.506753
validation error:	0.248300
2017-02-05 06:27:37,587 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:29:08,807 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-044.pkl
2017-02-05 06:29:10,749 INFO     epoch: 44 took 93.166s (0.001s in batching)
training loss:	0.505024
validation loss:	0.508547
validation error:	0.247300
2017-02-05 06:29:10,753 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:30:36,983 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-045.pkl
2017-02-05 06:30:38,917 INFO     epoch: 45 took 88.168s (0.001s in batching)
training loss:	0.504133
validation loss:	0.510942
validation error:	0.252700
2017-02-05 06:30:38,921 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:32:01,036 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-046.pkl
2017-02-05 06:32:02,843 INFO     epoch: 46 took 83.926s (0.001s in batching)
training loss:	0.503963
validation loss:	0.503200
validation error:	0.244600
2017-02-05 06:32:02,847 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:33:21,892 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-047.pkl
2017-02-05 06:33:23,707 INFO     epoch: 47 took 80.865s (0.001s in batching)
training loss:	0.503693
validation loss:	0.504868
validation error:	0.245700
2017-02-05 06:33:23,712 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:34:42,867 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-048.pkl
2017-02-05 06:34:44,700 INFO     epoch: 48 took 80.992s (0.001s in batching)
training loss:	0.502493
validation loss:	0.507751
validation error:	0.247900
2017-02-05 06:34:44,704 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:36:03,747 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-049.pkl
2017-02-05 06:36:05,569 INFO     epoch: 49 took 80.870s (0.001s in batching)
training loss:	0.502123
validation loss:	0.505477
validation error:	0.245600
2017-02-05 06:36:05,574 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:37:24,676 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-050.pkl
2017-02-05 06:37:26,509 INFO     epoch: 50 took 80.940s (0.001s in batching)
training loss:	0.501192
validation loss:	0.505345
validation error:	0.242800
2017-02-05 06:37:26,514 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:38:45,695 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-051.pkl
2017-02-05 06:38:47,502 INFO     epoch: 51 took 80.993s (0.001s in batching)
training loss:	0.501222
validation loss:	0.504506
validation error:	0.246100
2017-02-05 06:38:47,507 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:40:06,806 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-052.pkl
2017-02-05 06:40:08,631 INFO     epoch: 52 took 81.129s (0.001s in batching)
training loss:	0.500803
validation loss:	0.507444
validation error:	0.244000
2017-02-05 06:40:08,635 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:41:27,784 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-053.pkl
2017-02-05 06:41:29,624 INFO     epoch: 53 took 80.993s (0.001s in batching)
training loss:	0.500704
validation loss:	0.506166
validation error:	0.246900
2017-02-05 06:41:29,629 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:42:49,071 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-054.pkl
2017-02-05 06:42:50,886 INFO     epoch: 54 took 81.262s (0.001s in batching)
training loss:	0.499773
validation loss:	0.506920
validation error:	0.245900
2017-02-05 06:42:50,891 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:44:10,455 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-055.pkl
2017-02-05 06:44:12,266 INFO     epoch: 55 took 81.380s (0.001s in batching)
training loss:	0.500217
validation loss:	0.504531
validation error:	0.245700
2017-02-05 06:44:12,270 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:45:31,266 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-056.pkl
2017-02-05 06:45:33,098 INFO     epoch: 56 took 80.832s (0.001s in batching)
training loss:	0.498724
validation loss:	0.507061
validation error:	0.247900
2017-02-05 06:45:33,103 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:46:52,430 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-057.pkl
2017-02-05 06:46:54,248 INFO     epoch: 57 took 81.150s (0.001s in batching)
training loss:	0.498895
validation loss:	0.508868
validation error:	0.244200
2017-02-05 06:46:54,252 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:48:13,787 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-058.pkl
2017-02-05 06:48:15,612 INFO     epoch: 58 took 81.364s (0.001s in batching)
training loss:	0.498303
validation loss:	0.510333
validation error:	0.248800
2017-02-05 06:48:15,616 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:49:34,877 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-059.pkl
2017-02-05 06:49:36,697 INFO     epoch: 59 took 81.085s (0.001s in batching)
training loss:	0.497930
validation loss:	0.507643
validation error:	0.249700
2017-02-05 06:49:36,702 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:50:56,057 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-060.pkl
2017-02-05 06:50:57,877 INFO     epoch: 60 took 81.180s (0.001s in batching)
training loss:	0.497405
validation loss:	0.504046
validation error:	0.246700
2017-02-05 06:50:57,881 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:52:17,311 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-061.pkl
2017-02-05 06:52:19,123 INFO     epoch: 61 took 81.246s (0.001s in batching)
training loss:	0.496432
validation loss:	0.504960
validation error:	0.247000
2017-02-05 06:52:19,127 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:53:38,889 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-062.pkl
2017-02-05 06:53:40,710 INFO     epoch: 62 took 81.587s (0.001s in batching)
training loss:	0.496195
validation loss:	0.505228
validation error:	0.248900
2017-02-05 06:53:40,715 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:54:57,961 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-063.pkl
2017-02-05 06:54:59,742 INFO     epoch: 63 took 79.032s (0.001s in batching)
training loss:	0.496156
validation loss:	0.505766
validation error:	0.246500
2017-02-05 06:54:59,747 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:56:16,626 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-064.pkl
2017-02-05 06:56:18,405 INFO     epoch: 64 took 78.663s (0.001s in batching)
training loss:	0.495404
validation loss:	0.507941
validation error:	0.250900
2017-02-05 06:56:18,409 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:57:35,261 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-065.pkl
2017-02-05 06:57:37,028 INFO     epoch: 65 took 78.624s (0.001s in batching)
training loss:	0.496077
validation loss:	0.504394
validation error:	0.244100
2017-02-05 06:57:37,033 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 06:58:53,566 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-066.pkl
2017-02-05 06:58:55,340 INFO     epoch: 66 took 78.312s (0.001s in batching)
training loss:	0.494850
validation loss:	0.510722
validation error:	0.246000
2017-02-05 06:58:55,345 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:00:11,980 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-067.pkl
2017-02-05 07:00:13,749 INFO     epoch: 67 took 78.408s (0.001s in batching)
training loss:	0.494626
validation loss:	0.507050
validation error:	0.247300
2017-02-05 07:00:13,754 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:01:30,355 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-068.pkl
2017-02-05 07:01:32,120 INFO     epoch: 68 took 78.371s (0.001s in batching)
training loss:	0.493495
validation loss:	0.502154
validation error:	0.243400
2017-02-05 07:01:32,125 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:02:48,790 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-069.pkl
2017-02-05 07:02:50,569 INFO     epoch: 69 took 78.449s (0.001s in batching)
training loss:	0.493644
validation loss:	0.507593
validation error:	0.248500
2017-02-05 07:02:50,574 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:04:07,231 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-070.pkl
2017-02-05 07:04:09,003 INFO     epoch: 70 took 78.435s (0.001s in batching)
training loss:	0.493263
validation loss:	0.509431
validation error:	0.250500
2017-02-05 07:04:09,008 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:05:25,674 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-071.pkl
2017-02-05 07:05:27,465 INFO     epoch: 71 took 78.462s (0.001s in batching)
training loss:	0.492481
validation loss:	0.507676
validation error:	0.250600
2017-02-05 07:05:27,471 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:06:43,628 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-072.pkl
2017-02-05 07:06:45,386 INFO     epoch: 72 took 77.921s (0.001s in batching)
training loss:	0.492891
validation loss:	0.508409
validation error:	0.247800
2017-02-05 07:06:45,391 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:08:01,665 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-073.pkl
2017-02-05 07:08:03,416 INFO     epoch: 73 took 78.030s (0.001s in batching)
training loss:	0.491697
validation loss:	0.509806
validation error:	0.249800
2017-02-05 07:08:03,421 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:09:19,639 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-074.pkl
2017-02-05 07:09:21,392 INFO     epoch: 74 took 77.976s (0.001s in batching)
training loss:	0.492396
validation loss:	0.506446
validation error:	0.247100
2017-02-05 07:09:21,397 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:10:37,701 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-075.pkl
2017-02-05 07:10:39,460 INFO     epoch: 75 took 78.068s (0.001s in batching)
training loss:	0.491261
validation loss:	0.509691
validation error:	0.247600
2017-02-05 07:10:39,465 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:11:55,717 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-076.pkl
2017-02-05 07:11:57,472 INFO     epoch: 76 took 78.012s (0.001s in batching)
training loss:	0.490935
validation loss:	0.508988
validation error:	0.248200
2017-02-05 07:11:57,477 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:13:13,759 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-077.pkl
2017-02-05 07:13:15,515 INFO     epoch: 77 took 78.043s (0.001s in batching)
training loss:	0.490435
validation loss:	0.509395
validation error:	0.247600
2017-02-05 07:13:15,521 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:14:31,871 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-078.pkl
2017-02-05 07:14:33,637 INFO     epoch: 78 took 78.122s (0.001s in batching)
training loss:	0.489722
validation loss:	0.511411
validation error:	0.247000
2017-02-05 07:14:33,643 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:15:50,007 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-079.pkl
2017-02-05 07:15:51,763 INFO     epoch: 79 took 78.125s (0.001s in batching)
training loss:	0.489659
validation loss:	0.512442
validation error:	0.249100
2017-02-05 07:15:51,769 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:17:08,088 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-080.pkl
2017-02-05 07:17:09,847 INFO     epoch: 80 took 78.084s (0.001s in batching)
training loss:	0.488747
validation loss:	0.509441
validation error:	0.250700
2017-02-05 07:17:09,852 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:18:25,889 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-081.pkl
2017-02-05 07:18:27,630 INFO     epoch: 81 took 77.783s (0.001s in batching)
training loss:	0.488774
validation loss:	0.513067
validation error:	0.252700
2017-02-05 07:18:27,635 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:19:42,787 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-082.pkl
2017-02-05 07:19:44,524 INFO     epoch: 82 took 76.894s (0.001s in batching)
training loss:	0.488818
validation loss:	0.510571
validation error:	0.247600
2017-02-05 07:19:44,529 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:20:59,784 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-083.pkl
2017-02-05 07:21:01,527 INFO     epoch: 83 took 77.003s (0.001s in batching)
training loss:	0.488211
validation loss:	0.515543
validation error:	0.254000
2017-02-05 07:21:01,533 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:22:16,791 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-084.pkl
2017-02-05 07:22:18,536 INFO     epoch: 84 took 77.009s (0.001s in batching)
training loss:	0.488979
validation loss:	0.506299
validation error:	0.244900
2017-02-05 07:22:18,542 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:23:33,885 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-085.pkl
2017-02-05 07:23:35,628 INFO     epoch: 85 took 77.091s (0.001s in batching)
training loss:	0.487382
validation loss:	0.512441
validation error:	0.250400
2017-02-05 07:23:35,634 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:24:50,940 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-086.pkl
2017-02-05 07:24:52,685 INFO     epoch: 86 took 77.057s (0.001s in batching)
training loss:	0.487623
validation loss:	0.511089
validation error:	0.245300
2017-02-05 07:24:52,691 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:26:08,017 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-087.pkl
2017-02-05 07:26:09,776 INFO     epoch: 87 took 77.091s (0.001s in batching)
training loss:	0.487395
validation loss:	0.509933
validation error:	0.246400
2017-02-05 07:26:09,782 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:27:25,247 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-088.pkl
2017-02-05 07:27:26,991 INFO     epoch: 88 took 77.215s (0.001s in batching)
training loss:	0.486347
validation loss:	0.514410
validation error:	0.248400
2017-02-05 07:27:26,997 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:28:42,441 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-089.pkl
2017-02-05 07:28:44,197 INFO     epoch: 89 took 77.206s (0.001s in batching)
training loss:	0.486062
validation loss:	0.513359
validation error:	0.248300
2017-02-05 07:28:44,203 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:29:59,654 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-090.pkl
2017-02-05 07:30:01,426 INFO     epoch: 90 took 77.229s (0.001s in batching)
training loss:	0.485330
validation loss:	0.517513
validation error:	0.250600
2017-02-05 07:30:01,432 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:31:16,901 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-091.pkl
2017-02-05 07:31:18,660 INFO     epoch: 91 took 77.234s (0.001s in batching)
training loss:	0.485736
validation loss:	0.512096
validation error:	0.247900
2017-02-05 07:31:18,666 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:32:34,233 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-092.pkl
2017-02-05 07:32:35,997 INFO     epoch: 92 took 77.337s (0.001s in batching)
training loss:	0.485075
validation loss:	0.518929
validation error:	0.249900
2017-02-05 07:32:36,003 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:33:51,557 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-093.pkl
2017-02-05 07:33:53,344 INFO     epoch: 93 took 77.347s (0.001s in batching)
training loss:	0.484472
validation loss:	0.515012
validation error:	0.252100
2017-02-05 07:33:53,350 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:35:08,935 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-094.pkl
2017-02-05 07:35:10,692 INFO     epoch: 94 took 77.348s (0.001s in batching)
training loss:	0.485445
validation loss:	0.518028
validation error:	0.257300
2017-02-05 07:35:10,698 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:36:26,332 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-095.pkl
2017-02-05 07:36:28,115 INFO     epoch: 95 took 77.423s (0.001s in batching)
training loss:	0.484753
validation loss:	0.514397
validation error:	0.249400
2017-02-05 07:36:28,121 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:37:43,760 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-096.pkl
2017-02-05 07:37:45,515 INFO     epoch: 96 took 77.401s (0.001s in batching)
training loss:	0.483951
validation loss:	0.515369
validation error:	0.250600
2017-02-05 07:37:45,522 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:39:01,160 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-097.pkl
2017-02-05 07:39:02,917 INFO     epoch: 97 took 77.401s (0.001s in batching)
training loss:	0.483671
validation loss:	0.519428
validation error:	0.250500
2017-02-05 07:39:02,923 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:40:18,670 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-098.pkl
2017-02-05 07:40:20,426 INFO     epoch: 98 took 77.509s (0.001s in batching)
training loss:	0.483595
validation loss:	0.516100
validation error:	0.247900
2017-02-05 07:40:20,432 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
2017-02-05 07:41:36,109 INFO     Saving network params to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/epoch-099.pkl
2017-02-05 07:41:37,867 INFO     epoch: 99 took 77.441s (0.001s in batching)
training loss:	0.484254
validation loss:	0.518968
validation error:	0.253200
2017-02-05 07:41:37,873 INFO     Wrote output to trainNN/out/v048-finunified-4-ga18ab48-dirty:lstm-best-context-2000ms/config.json
