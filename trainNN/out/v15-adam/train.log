2016-11-25 22:59:12 >>> version=v15-adam
2016-11-25 22:59:12 >>> loading config file extract_pfiles_python/out/v09-without-frame-limiting-context40/config.json
2016-11-25 22:59:12 >>> loading numpy file extract_pfiles_python/out/v09-without-frame-limiting-context40/train.npz
2016-11-25 22:59:15 >>> loading numpy file extract_pfiles_python/out/v09-without-frame-limiting-context40/validate.npz
2016-11-25 22:59:15 >>> Using fuzzy_newbob as schedulung method.
2016-11-25 22:59:15 >>> Training network with 21452 trainable out of 21452 total params.
2016-11-25 22:59:15 >>> Using adam with learning_rate=0.001000
2016-11-25 22:59:15 >>> Compiling theano functions...
2016-11-25 22:59:16 >>> Starting training...
2016-11-25 23:00:10 >>>   training loss:	0.650094
2016-11-25 23:00:10 >>> Saving network params to trainNN/out/v15-adam/epoch-000.pkl
2016-11-25 23:00:12 >>> epoch: 0 validation error:		0.373708
2016-11-25 23:01:04 >>>   training loss:	0.638915
2016-11-25 23:01:04 >>> Saving network params to trainNN/out/v15-adam/epoch-001.pkl
2016-11-25 23:01:06 >>> epoch: 1 validation error:		0.364060
2016-11-25 23:01:59 >>>   training loss:	0.633599
2016-11-25 23:01:59 >>> Saving network params to trainNN/out/v15-adam/epoch-002.pkl
2016-11-25 23:02:00 >>> epoch: 2 validation error:		0.361542
2016-11-25 23:02:54 >>>   training loss:	0.630568
2016-11-25 23:02:54 >>> Saving network params to trainNN/out/v15-adam/epoch-003.pkl
2016-11-25 23:02:56 >>> epoch: 3 validation error:		0.359538
2016-11-25 23:03:50 >>>   training loss:	0.628331
2016-11-25 23:03:50 >>> Saving network params to trainNN/out/v15-adam/epoch-004.pkl
2016-11-25 23:03:52 >>> epoch: 4 validation error:		0.357769
2016-11-25 23:04:43 >>>   training loss:	0.626550
2016-11-25 23:04:43 >>> Saving network params to trainNN/out/v15-adam/epoch-005.pkl
2016-11-25 23:04:45 >>> epoch: 5 validation error:		0.358605
2016-11-25 23:04:45 >>> Loading old params from trainNN/out/v15-adam/epoch-004.pkl
2016-11-25 23:04:45 >>> fuzzy_newbob: Updating adam with learning_rate=0.000500
2016-11-25 23:04:45 >>> Re-compiling train function...
2016-11-25 23:05:39 >>>   training loss:	0.625197
2016-11-25 23:05:39 >>> Saving network params to trainNN/out/v15-adam/epoch-006.pkl
2016-11-25 23:05:41 >>> epoch: 6 validation error:		0.355838
2016-11-25 23:06:35 >>>   training loss:	0.624230
2016-11-25 23:06:35 >>> Saving network params to trainNN/out/v15-adam/epoch-007.pkl
2016-11-25 23:06:37 >>> epoch: 7 validation error:		0.356160
2016-11-25 23:06:37 >>> Loading old params from trainNN/out/v15-adam/epoch-006.pkl
2016-11-25 23:06:37 >>> fuzzy_newbob: Updating adam with learning_rate=0.000250
2016-11-25 23:06:37 >>> Re-compiling train function...
2016-11-25 23:07:29 >>>   training loss:	0.623508
2016-11-25 23:07:29 >>> Saving network params to trainNN/out/v15-adam/epoch-008.pkl
2016-11-25 23:07:31 >>> epoch: 8 validation error:		0.354815
2016-11-25 23:08:16 >>>   training loss:	0.622965
2016-11-25 23:08:16 >>> Saving network params to trainNN/out/v15-adam/epoch-009.pkl
2016-11-25 23:08:18 >>> epoch: 9 validation error:		0.354850
2016-11-25 23:08:18 >>> Loading old params from trainNN/out/v15-adam/epoch-008.pkl
2016-11-25 23:08:18 >>> fuzzy_newbob: Updating adam with learning_rate=0.000125
2016-11-25 23:08:18 >>> Re-compiling train function...
2016-11-25 23:09:03 >>>   training loss:	0.622622
2016-11-25 23:09:03 >>> Saving network params to trainNN/out/v15-adam/epoch-010.pkl
2016-11-25 23:09:05 >>> epoch: 10 validation error:		0.353903
2016-11-25 23:09:49 >>>   training loss:	0.622351
2016-11-25 23:09:49 >>> Saving network params to trainNN/out/v15-adam/epoch-011.pkl
2016-11-25 23:09:51 >>> epoch: 11 validation error:		0.353482
2016-11-25 23:10:34 >>>   training loss:	0.622135
2016-11-25 23:10:34 >>> Saving network params to trainNN/out/v15-adam/epoch-012.pkl
2016-11-25 23:10:36 >>> epoch: 12 validation error:		0.353465
2016-11-25 23:11:28 >>>   training loss:	0.621911
2016-11-25 23:11:28 >>> Saving network params to trainNN/out/v15-adam/epoch-013.pkl
2016-11-25 23:11:30 >>> epoch: 13 validation error:		0.353099
2016-11-25 23:12:24 >>>   training loss:	0.621717
2016-11-25 23:12:24 >>> Saving network params to trainNN/out/v15-adam/epoch-014.pkl
2016-11-25 23:12:26 >>> epoch: 14 validation error:		0.353825
2016-11-25 23:12:26 >>> Loading old params from trainNN/out/v15-adam/epoch-013.pkl
2016-11-25 23:12:26 >>> fuzzy_newbob: Updating adam with learning_rate=0.000063
2016-11-25 23:12:26 >>> Re-compiling train function...
2016-11-25 23:13:20 >>>   training loss:	0.621474
2016-11-25 23:13:20 >>> Saving network params to trainNN/out/v15-adam/epoch-015.pkl
2016-11-25 23:13:22 >>> epoch: 15 validation error:		0.353140
2016-11-25 23:13:22 >>> Loading old params from trainNN/out/v15-adam/epoch-013.pkl
2016-11-25 23:13:22 >>> fuzzy_newbob: Updating adam with learning_rate=0.000031
2016-11-25 23:13:22 >>> Re-compiling train function...
2016-11-25 23:14:14 >>>   training loss:	0.621374
2016-11-25 23:14:14 >>> Saving network params to trainNN/out/v15-adam/epoch-016.pkl
2016-11-25 23:14:15 >>> epoch: 16 validation error:		0.352968
2016-11-25 23:15:07 >>>   training loss:	0.621296
2016-11-25 23:15:07 >>> Saving network params to trainNN/out/v15-adam/epoch-017.pkl
2016-11-25 23:15:09 >>> epoch: 17 validation error:		0.353020
2016-11-25 23:15:09 >>> Loading old params from trainNN/out/v15-adam/epoch-016.pkl
2016-11-25 23:15:09 >>> fuzzy_newbob: Updating adam with learning_rate=0.000016
2016-11-25 23:15:09 >>> Re-compiling train function...
2016-11-25 23:16:02 >>>   training loss:	0.621239
2016-11-25 23:16:02 >>> Saving network params to trainNN/out/v15-adam/epoch-018.pkl
2016-11-25 23:16:04 >>> epoch: 18 validation error:		0.353029
2016-11-25 23:16:04 >>> Loading old params from trainNN/out/v15-adam/epoch-016.pkl
2016-11-25 23:16:04 >>> fuzzy_newbob: Updating adam with learning_rate=0.000008
2016-11-25 23:16:04 >>> Re-compiling train function...
2016-11-25 23:16:58 >>>   training loss:	0.621211
2016-11-25 23:16:58 >>> Saving network params to trainNN/out/v15-adam/epoch-019.pkl
2016-11-25 23:17:00 >>> epoch: 19 validation error:		0.352936
2016-11-25 23:17:51 >>>   training loss:	0.621187
2016-11-25 23:17:51 >>> Saving network params to trainNN/out/v15-adam/epoch-020.pkl
2016-11-25 23:17:53 >>> epoch: 20 validation error:		0.352718
2016-11-25 23:18:45 >>>   training loss:	0.621172
2016-11-25 23:18:45 >>> Saving network params to trainNN/out/v15-adam/epoch-021.pkl
2016-11-25 23:18:47 >>> epoch: 21 validation error:		0.352893
2016-11-25 23:18:47 >>> Loading old params from trainNN/out/v15-adam/epoch-020.pkl
2016-11-25 23:18:47 >>> fuzzy_newbob: Updating adam with learning_rate=0.000004
2016-11-25 23:18:47 >>> Re-compiling train function...
2016-11-25 23:19:39 >>>   training loss:	0.621154
2016-11-25 23:19:39 >>> Saving network params to trainNN/out/v15-adam/epoch-022.pkl
2016-11-25 23:19:41 >>> epoch: 22 validation error:		0.352829
2016-11-25 23:19:41 >>> Loading old params from trainNN/out/v15-adam/epoch-020.pkl
2016-11-25 23:19:41 >>> fuzzy_newbob: Updating adam with learning_rate=0.000002
2016-11-25 23:19:41 >>> Re-compiling train function...
2016-11-25 23:20:34 >>>   training loss:	0.621143
2016-11-25 23:20:34 >>> Saving network params to trainNN/out/v15-adam/epoch-023.pkl
2016-11-25 23:20:36 >>> epoch: 23 validation error:		0.352776
2016-11-25 23:20:36 >>> learning rate below 1e-06, ending
2016-11-25 23:20:36 >>> Wrote output to trainNN/out/v15-adam/config.json
