2016-11-25 16:36:56 >>> version=v09-pitchnormalization4-dirty
2016-11-25 16:36:56 >>> loading config file extract_pfiles_python/out/v09-pitchnormalization4-context40/config.json
2016-11-25 16:36:56 >>> loading numpy file extract_pfiles_python/out/v09-pitchnormalization4-context40/train.npz
2016-11-25 16:36:59 >>> loading numpy file extract_pfiles_python/out/v09-pitchnormalization4-context40/validate.npz
2016-11-25 16:37:00 >>> Using fuzzy_newbob as schedulung method.
2016-11-25 16:37:00 >>> Training network with 21452 trainable out of 21452 total params.
2016-11-25 16:37:00 >>> Using adadelta with learning_rate=1.000000
2016-11-25 16:37:00 >>> Compiling theano functions...
2016-11-25 16:37:01 >>> Starting training...
2016-11-25 16:37:19 >>>   training loss:	0.576785
2016-11-25 16:37:19 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-000.pkl
2016-11-25 16:37:20 >>> epoch: 0 validation error:		0.341324
2016-11-25 16:37:36 >>>   training loss:	0.348903
2016-11-25 16:37:36 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-001.pkl
2016-11-25 16:37:38 >>> epoch: 1 validation error:		0.071331
2016-11-25 16:37:54 >>>   training loss:	0.283668
2016-11-25 16:37:54 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-002.pkl
2016-11-25 16:37:55 >>> epoch: 2 validation error:		0.103995
2016-11-25 16:37:55 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-001.pkl
2016-11-25 16:37:55 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.800000
2016-11-25 16:37:55 >>> Re-compiling train function...
2016-11-25 16:38:12 >>>   training loss:	0.260372
2016-11-25 16:38:12 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-003.pkl
2016-11-25 16:38:13 >>> epoch: 3 validation error:		0.065969
2016-11-25 16:38:31 >>>   training loss:	0.244414
2016-11-25 16:38:31 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-004.pkl
2016-11-25 16:38:32 >>> epoch: 4 validation error:		0.088183
2016-11-25 16:38:32 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-003.pkl
2016-11-25 16:38:32 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.640000
2016-11-25 16:38:32 >>> Re-compiling train function...
2016-11-25 16:38:48 >>>   training loss:	0.229559
2016-11-25 16:38:48 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-005.pkl
2016-11-25 16:38:49 >>> epoch: 5 validation error:		0.062407
2016-11-25 16:39:07 >>>   training loss:	0.220337
2016-11-25 16:39:07 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-006.pkl
2016-11-25 16:39:08 >>> epoch: 6 validation error:		0.068188
2016-11-25 16:39:08 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-005.pkl
2016-11-25 16:39:08 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.512000
2016-11-25 16:39:08 >>> Re-compiling train function...
2016-11-25 16:39:26 >>>   training loss:	0.209173
2016-11-25 16:39:26 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-007.pkl
2016-11-25 16:39:27 >>> epoch: 7 validation error:		0.060520
2016-11-25 16:39:42 >>>   training loss:	0.203450
2016-11-25 16:39:42 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-008.pkl
2016-11-25 16:39:43 >>> epoch: 8 validation error:		0.118010
2016-11-25 16:39:43 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-007.pkl
2016-11-25 16:39:43 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.409600
2016-11-25 16:39:43 >>> Re-compiling train function...
2016-11-25 16:39:58 >>>   training loss:	0.195452
2016-11-25 16:39:58 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-009.pkl
2016-11-25 16:39:59 >>> epoch: 9 validation error:		0.075720
2016-11-25 16:39:59 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-007.pkl
2016-11-25 16:39:59 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.327680
2016-11-25 16:39:59 >>> Re-compiling train function...
2016-11-25 16:40:15 >>>   training loss:	0.190482
2016-11-25 16:40:15 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-010.pkl
2016-11-25 16:40:16 >>> epoch: 10 validation error:		0.078029
2016-11-25 16:40:16 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-007.pkl
2016-11-25 16:40:16 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.262144
2016-11-25 16:40:16 >>> Re-compiling train function...
2016-11-25 16:40:33 >>>   training loss:	0.187601
2016-11-25 16:40:33 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-011.pkl
2016-11-25 16:40:35 >>> epoch: 11 validation error:		0.057792
2016-11-25 16:40:51 >>>   training loss:	0.182825
2016-11-25 16:40:51 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-012.pkl
2016-11-25 16:40:53 >>> epoch: 12 validation error:		0.057858
2016-11-25 16:40:53 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-011.pkl
2016-11-25 16:40:53 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.209715
2016-11-25 16:40:53 >>> Re-compiling train function...
2016-11-25 16:41:09 >>>   training loss:	0.180851
2016-11-25 16:41:09 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-013.pkl
2016-11-25 16:41:10 >>> epoch: 13 validation error:		0.054835
2016-11-25 16:41:27 >>>   training loss:	0.176979
2016-11-25 16:41:27 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-014.pkl
2016-11-25 16:41:28 >>> epoch: 14 validation error:		0.065143
2016-11-25 16:41:28 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-013.pkl
2016-11-25 16:41:28 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.167772
2016-11-25 16:41:28 >>> Re-compiling train function...
2016-11-25 16:41:45 >>>   training loss:	0.175513
2016-11-25 16:41:45 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-015.pkl
2016-11-25 16:41:46 >>> epoch: 15 validation error:		0.054214
2016-11-25 16:42:04 >>>   training loss:	0.172674
2016-11-25 16:42:04 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-016.pkl
2016-11-25 16:42:05 >>> epoch: 16 validation error:		0.053485
2016-11-25 16:42:23 >>>   training loss:	0.170181
2016-11-25 16:42:23 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:42:25 >>> epoch: 17 validation error:		0.052858
2016-11-25 16:42:48 >>>   training loss:	0.167731
2016-11-25 16:42:48 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-018.pkl
2016-11-25 16:42:49 >>> epoch: 18 validation error:		0.055082
2016-11-25 16:42:49 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:42:49 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.134218
2016-11-25 16:42:49 >>> Re-compiling train function...
2016-11-25 16:43:10 >>>   training loss:	0.166410
2016-11-25 16:43:10 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-019.pkl
2016-11-25 16:43:12 >>> epoch: 19 validation error:		0.055836
2016-11-25 16:43:12 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:43:12 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.107374
2016-11-25 16:43:12 >>> Re-compiling train function...
2016-11-25 16:43:27 >>>   training loss:	0.165648
2016-11-25 16:43:27 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-020.pkl
2016-11-25 16:43:28 >>> epoch: 20 validation error:		0.053618
2016-11-25 16:43:28 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:43:28 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.085899
2016-11-25 16:43:28 >>> Re-compiling train function...
2016-11-25 16:43:43 >>>   training loss:	0.165023
2016-11-25 16:43:43 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-021.pkl
2016-11-25 16:43:44 >>> epoch: 21 validation error:		0.059833
2016-11-25 16:43:44 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:43:44 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.068719
2016-11-25 16:43:44 >>> Re-compiling train function...
2016-11-25 16:44:00 >>>   training loss:	0.164592
2016-11-25 16:44:00 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-022.pkl
2016-11-25 16:44:01 >>> epoch: 22 validation error:		0.054109
2016-11-25 16:44:01 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:44:01 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.054976
2016-11-25 16:44:01 >>> Re-compiling train function...
2016-11-25 16:44:16 >>>   training loss:	0.164380
2016-11-25 16:44:16 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-023.pkl
2016-11-25 16:44:17 >>> epoch: 23 validation error:		0.053271
2016-11-25 16:44:17 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:44:17 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.043980
2016-11-25 16:44:17 >>> Re-compiling train function...
2016-11-25 16:44:38 >>>   training loss:	0.164167
2016-11-25 16:44:38 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-024.pkl
2016-11-25 16:44:39 >>> epoch: 24 validation error:		0.054908
2016-11-25 16:44:39 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:44:39 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.035184
2016-11-25 16:44:39 >>> Re-compiling train function...
2016-11-25 16:44:56 >>>   training loss:	0.163973
2016-11-25 16:44:56 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-025.pkl
2016-11-25 16:44:57 >>> epoch: 25 validation error:		0.054130
2016-11-25 16:44:57 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:44:57 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.028147
2016-11-25 16:44:57 >>> Re-compiling train function...
2016-11-25 16:45:12 >>>   training loss:	0.163893
2016-11-25 16:45:12 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-026.pkl
2016-11-25 16:45:13 >>> epoch: 26 validation error:		0.054449
2016-11-25 16:45:13 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:45:13 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.022518
2016-11-25 16:45:13 >>> Re-compiling train function...
2016-11-25 16:45:31 >>>   training loss:	0.163799
2016-11-25 16:45:31 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-027.pkl
2016-11-25 16:45:32 >>> epoch: 27 validation error:		0.053949
2016-11-25 16:45:32 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:45:32 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.018014
2016-11-25 16:45:32 >>> Re-compiling train function...
2016-11-25 16:45:49 >>>   training loss:	0.163715
2016-11-25 16:45:49 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-028.pkl
2016-11-25 16:45:50 >>> epoch: 28 validation error:		0.054009
2016-11-25 16:45:50 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:45:50 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.014412
2016-11-25 16:45:50 >>> Re-compiling train function...
2016-11-25 16:46:08 >>>   training loss:	0.163618
2016-11-25 16:46:08 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-029.pkl
2016-11-25 16:46:09 >>> epoch: 29 validation error:		0.053777
2016-11-25 16:46:09 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:46:09 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.011529
2016-11-25 16:46:09 >>> Re-compiling train function...
2016-11-25 16:46:24 >>>   training loss:	0.163612
2016-11-25 16:46:24 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-030.pkl
2016-11-25 16:46:26 >>> epoch: 30 validation error:		0.056017
2016-11-25 16:46:26 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:46:26 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.009223
2016-11-25 16:46:26 >>> Re-compiling train function...
2016-11-25 16:46:42 >>>   training loss:	0.163583
2016-11-25 16:46:42 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-031.pkl
2016-11-25 16:46:43 >>> epoch: 31 validation error:		0.055161
2016-11-25 16:46:43 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:46:43 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.007379
2016-11-25 16:46:43 >>> Re-compiling train function...
2016-11-25 16:46:59 >>> received exit signal, waiting for epoch to finish...
2016-11-25 16:47:00 >>>   training loss:	0.163546
2016-11-25 16:47:00 >>> Saving network params to trainNN/out/v09-pitchnormalization4-dirty/epoch-032.pkl
2016-11-25 16:47:01 >>> epoch: 32 validation error:		0.054103
2016-11-25 16:47:01 >>> Loading old params from trainNN/out/v09-pitchnormalization4-dirty/epoch-017.pkl
2016-11-25 16:47:01 >>> fuzzy_newbob: Updating adadelta with learning_rate=0.005903
2016-11-25 16:47:01 >>> Re-compiling train function...
2016-11-25 16:47:02 >>> Wrote output to trainNN/out/v09-pitchnormalization4-dirty/config.json
