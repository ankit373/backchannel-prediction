2017-02-05 21:50:39,240 DEBUG    version=v049-finunified-3-ge1cb642:lstm-best-layers-50-20
2017-02-05 21:50:39,242 INFO     Open DBase(data/db/all240302-spk.dat, data/db/all240302-spk.idx, mode='r')
2017-02-05 21:50:50,703 DEBUG    loading cached extracted data from data/cache/extract-7a00b23850576d60137fa78432d8dfda09ea0f343092bd09848f21113b1acfd0.pickle
2017-02-05 21:50:52,042 DEBUG    set input dim to 9
2017-02-05 21:50:52,044 DEBUG    input dim = 9
2017-02-05 21:50:52,061 DEBUG    shuffling batches
2017-02-05 21:50:57,071 DEBUG    shuffling done
2017-02-05 21:50:57,071 DEBUG    loading data into ram
2017-02-05 21:50:57,200 DEBUG    loading data took 0.128s (cpu: 0.128s)
2017-02-05 21:50:57,521 DEBUG    set input dim to 9
2017-02-05 21:50:57,521 DEBUG    input dim = 9
2017-02-05 21:50:57,551 DEBUG    shuffling batches
2017-02-05 21:50:58,047 DEBUG    shuffling done
2017-02-05 21:50:58,047 DEBUG    loading data into ram
2017-02-05 21:50:58,061 DEBUG    loading data took 0.013s (cpu: 0.013s)
2017-02-05 21:50:58,191 DEBUG    Applying L2 regularization with 0.000100
2017-02-05 21:50:58,319 INFO     Training network with 17932 trainable out of 18072 total params.
2017-02-05 21:50:59,184 DEBUG    Using adam with learning_rate=0.001000
2017-02-05 21:51:39,390 DEBUG    Starting training...
2017-02-05 21:53:13,283 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-000.pkl
2017-02-05 21:53:15,421 INFO     epoch: 0 took 96.030s (0.001s in batching)
training loss:	0.621800
validation loss:	0.581440
validation error:	0.299100
2017-02-05 21:53:15,424 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 21:54:48,768 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-001.pkl
2017-02-05 21:54:50,900 INFO     epoch: 1 took 95.479s (0.001s in batching)
training loss:	0.587023
validation loss:	0.573741
validation error:	0.297500
2017-02-05 21:54:50,902 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 21:56:24,602 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-002.pkl
2017-02-05 21:56:26,731 INFO     epoch: 2 took 95.831s (0.001s in batching)
training loss:	0.581730
validation loss:	0.573510
validation error:	0.296600
2017-02-05 21:56:26,734 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 21:58:00,657 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-003.pkl
2017-02-05 21:58:02,852 INFO     epoch: 3 took 96.121s (0.001s in batching)
training loss:	0.578246
validation loss:	0.565801
validation error:	0.292200
2017-02-05 21:58:02,855 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 21:59:30,478 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-004.pkl
2017-02-05 21:59:32,037 INFO     epoch: 4 took 89.185s (0.001s in batching)
training loss:	0.575205
validation loss:	0.563720
validation error:	0.288900
2017-02-05 21:59:32,039 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:00:42,190 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-005.pkl
2017-02-05 22:00:43,905 INFO     epoch: 5 took 71.868s (0.001s in batching)
training loss:	0.573030
validation loss:	0.566352
validation error:	0.289300
2017-02-05 22:00:43,908 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:02:14,191 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-006.pkl
2017-02-05 22:02:16,394 INFO     epoch: 6 took 92.489s (0.001s in batching)
training loss:	0.569955
validation loss:	0.558577
validation error:	0.287300
2017-02-05 22:02:16,398 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:03:50,720 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-007.pkl
2017-02-05 22:03:52,905 INFO     epoch: 7 took 96.511s (0.002s in batching)
training loss:	0.567416
validation loss:	0.563551
validation error:	0.285300
2017-02-05 22:03:52,908 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:05:27,180 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-008.pkl
2017-02-05 22:05:29,365 INFO     epoch: 8 took 96.461s (0.001s in batching)
training loss:	0.565218
validation loss:	0.557815
validation error:	0.280100
2017-02-05 22:05:29,369 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:07:03,616 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-009.pkl
2017-02-05 22:07:05,813 INFO     epoch: 9 took 96.448s (0.001s in batching)
training loss:	0.561722
validation loss:	0.556053
validation error:	0.282000
2017-02-05 22:07:05,817 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:08:40,318 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-010.pkl
2017-02-05 22:08:42,472 INFO     epoch: 10 took 96.659s (0.001s in batching)
training loss:	0.560695
validation loss:	0.551998
validation error:	0.276700
2017-02-05 22:08:42,475 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:10:16,571 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-011.pkl
2017-02-05 22:10:18,777 INFO     epoch: 11 took 96.304s (0.001s in batching)
training loss:	0.558728
validation loss:	0.548295
validation error:	0.274800
2017-02-05 22:10:18,780 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:11:52,904 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-012.pkl
2017-02-05 22:11:55,089 INFO     epoch: 12 took 96.312s (0.001s in batching)
training loss:	0.557684
validation loss:	0.549129
validation error:	0.277400
2017-02-05 22:11:55,092 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:13:29,634 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-013.pkl
2017-02-05 22:13:31,824 INFO     epoch: 13 took 96.735s (0.001s in batching)
training loss:	0.555730
validation loss:	0.545818
validation error:	0.275500
2017-02-05 22:13:31,827 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:15:06,200 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-014.pkl
2017-02-05 22:15:08,358 INFO     epoch: 14 took 96.534s (0.001s in batching)
training loss:	0.554185
validation loss:	0.543095
validation error:	0.271900
2017-02-05 22:15:08,361 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:16:42,471 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-015.pkl
2017-02-05 22:16:44,616 INFO     epoch: 15 took 96.258s (0.001s in batching)
training loss:	0.553281
validation loss:	0.541656
validation error:	0.266900
2017-02-05 22:16:44,619 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:18:18,778 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-016.pkl
2017-02-05 22:18:20,964 INFO     epoch: 16 took 96.348s (0.001s in batching)
training loss:	0.551485
validation loss:	0.540709
validation error:	0.269400
2017-02-05 22:18:20,968 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:19:55,102 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-017.pkl
2017-02-05 22:19:57,290 INFO     epoch: 17 took 96.326s (0.001s in batching)
training loss:	0.550218
validation loss:	0.541417
validation error:	0.269600
2017-02-05 22:19:57,295 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:21:31,502 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-018.pkl
2017-02-05 22:21:33,629 INFO     epoch: 18 took 96.338s (0.001s in batching)
training loss:	0.549739
validation loss:	0.538478
validation error:	0.269700
2017-02-05 22:21:33,632 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:23:07,558 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-019.pkl
2017-02-05 22:23:09,776 INFO     epoch: 19 took 96.148s (0.001s in batching)
training loss:	0.548940
validation loss:	0.540914
validation error:	0.269700
2017-02-05 22:23:09,779 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:24:43,448 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-020.pkl
2017-02-05 22:24:45,571 INFO     epoch: 20 took 95.795s (0.001s in batching)
training loss:	0.548131
validation loss:	0.538565
validation error:	0.268300
2017-02-05 22:24:45,575 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:26:19,483 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-021.pkl
2017-02-05 22:26:21,697 INFO     epoch: 21 took 96.126s (0.001s in batching)
training loss:	0.547192
validation loss:	0.537833
validation error:	0.268700
2017-02-05 22:26:21,702 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:27:56,336 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-022.pkl
2017-02-05 22:27:58,505 INFO     epoch: 22 took 96.808s (0.001s in batching)
training loss:	0.546548
validation loss:	0.537787
validation error:	0.264200
2017-02-05 22:27:58,510 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:29:32,832 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-023.pkl
2017-02-05 22:29:35,040 INFO     epoch: 23 took 96.535s (0.001s in batching)
training loss:	0.546367
validation loss:	0.537235
validation error:	0.268400
2017-02-05 22:29:35,045 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:31:09,138 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-024.pkl
2017-02-05 22:31:11,328 INFO     epoch: 24 took 96.288s (0.001s in batching)
training loss:	0.545913
validation loss:	0.541536
validation error:	0.270900
2017-02-05 22:31:11,332 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:32:45,741 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-025.pkl
2017-02-05 22:32:47,943 INFO     epoch: 25 took 96.614s (0.001s in batching)
training loss:	0.544287
validation loss:	0.536854
validation error:	0.263600
2017-02-05 22:32:47,948 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:34:22,365 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-026.pkl
2017-02-05 22:34:24,566 INFO     epoch: 26 took 96.623s (0.001s in batching)
training loss:	0.543794
validation loss:	0.533557
validation error:	0.265500
2017-02-05 22:34:24,570 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:35:58,452 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-027.pkl
2017-02-05 22:36:00,668 INFO     epoch: 27 took 96.102s (0.001s in batching)
training loss:	0.543144
validation loss:	0.537058
validation error:	0.268200
2017-02-05 22:36:00,671 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:37:24,693 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-028.pkl
2017-02-05 22:37:26,393 INFO     epoch: 28 took 85.725s (0.001s in batching)
training loss:	0.541933
validation loss:	0.534215
validation error:	0.262100
2017-02-05 22:37:26,397 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:38:57,255 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-029.pkl
2017-02-05 22:38:59,414 INFO     epoch: 29 took 93.021s (0.001s in batching)
training loss:	0.540846
validation loss:	0.531611
validation error:	0.267000
2017-02-05 22:38:59,418 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:40:32,786 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-030.pkl
2017-02-05 22:40:34,946 INFO     epoch: 30 took 95.532s (0.001s in batching)
training loss:	0.540689
validation loss:	0.533082
validation error:	0.268400
2017-02-05 22:40:34,952 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:42:08,614 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-031.pkl
2017-02-05 22:42:10,786 INFO     epoch: 31 took 95.840s (0.001s in batching)
training loss:	0.539779
validation loss:	0.533206
validation error:	0.266300
2017-02-05 22:42:10,790 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:43:44,659 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-032.pkl
2017-02-05 22:43:46,831 INFO     epoch: 32 took 96.045s (0.001s in batching)
training loss:	0.538704
validation loss:	0.529782
validation error:	0.263300
2017-02-05 22:43:46,836 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:45:20,202 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-033.pkl
2017-02-05 22:45:22,464 INFO     epoch: 33 took 95.633s (0.001s in batching)
training loss:	0.537411
validation loss:	0.526050
validation error:	0.261700
2017-02-05 22:45:22,469 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:46:55,349 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-034.pkl
2017-02-05 22:46:57,545 INFO     epoch: 34 took 95.081s (0.001s in batching)
training loss:	0.537481
validation loss:	0.530430
validation error:	0.265400
2017-02-05 22:46:57,550 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:48:29,647 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-035.pkl
2017-02-05 22:48:31,786 INFO     epoch: 35 took 94.241s (0.001s in batching)
training loss:	0.536337
validation loss:	0.533057
validation error:	0.265400
2017-02-05 22:48:31,791 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:50:05,466 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-036.pkl
2017-02-05 22:50:07,630 INFO     epoch: 36 took 95.843s (0.001s in batching)
training loss:	0.536371
validation loss:	0.527869
validation error:	0.263700
2017-02-05 22:50:07,634 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:51:41,342 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-037.pkl
2017-02-05 22:51:43,502 INFO     epoch: 37 took 95.872s (0.001s in batching)
training loss:	0.535393
validation loss:	0.530421
validation error:	0.267000
2017-02-05 22:51:43,507 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:53:17,118 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-038.pkl
2017-02-05 22:53:19,308 INFO     epoch: 38 took 95.806s (0.001s in batching)
training loss:	0.534916
validation loss:	0.527495
validation error:	0.260900
2017-02-05 22:53:19,312 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:54:53,453 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-039.pkl
2017-02-05 22:54:55,656 INFO     epoch: 39 took 96.348s (0.001s in batching)
training loss:	0.534321
validation loss:	0.527090
validation error:	0.263400
2017-02-05 22:54:55,660 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:56:29,306 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-040.pkl
2017-02-05 22:56:31,470 INFO     epoch: 40 took 95.814s (0.001s in batching)
training loss:	0.534560
validation loss:	0.524906
validation error:	0.260900
2017-02-05 22:56:31,475 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:58:04,920 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-041.pkl
2017-02-05 22:58:07,111 INFO     epoch: 41 took 95.641s (0.001s in batching)
training loss:	0.533830
validation loss:	0.525782
validation error:	0.262800
2017-02-05 22:58:07,115 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 22:59:40,555 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-042.pkl
2017-02-05 22:59:42,723 INFO     epoch: 42 took 95.612s (0.001s in batching)
training loss:	0.533018
validation loss:	0.522841
validation error:	0.261800
2017-02-05 22:59:42,727 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:01:16,312 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-043.pkl
2017-02-05 23:01:18,473 INFO     epoch: 43 took 95.751s (0.001s in batching)
training loss:	0.533045
validation loss:	0.524054
validation error:	0.260100
2017-02-05 23:01:18,479 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:02:52,417 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-044.pkl
2017-02-05 23:02:54,536 INFO     epoch: 44 took 96.063s (0.001s in batching)
training loss:	0.532151
validation loss:	0.525413
validation error:	0.262100
2017-02-05 23:02:54,540 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:04:28,218 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-045.pkl
2017-02-05 23:04:30,408 INFO     epoch: 45 took 95.872s (0.001s in batching)
training loss:	0.531888
validation loss:	0.522431
validation error:	0.257300
2017-02-05 23:04:30,413 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:06:04,250 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-046.pkl
2017-02-05 23:06:06,427 INFO     epoch: 46 took 96.019s (0.001s in batching)
training loss:	0.531515
validation loss:	0.523081
validation error:	0.260600
2017-02-05 23:06:06,431 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:07:40,501 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-047.pkl
2017-02-05 23:07:42,675 INFO     epoch: 47 took 96.248s (0.001s in batching)
training loss:	0.530388
validation loss:	0.527314
validation error:	0.262600
2017-02-05 23:07:42,680 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:09:16,509 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-048.pkl
2017-02-05 23:09:18,694 INFO     epoch: 48 took 96.018s (0.001s in batching)
training loss:	0.530147
validation loss:	0.522640
validation error:	0.261900
2017-02-05 23:09:18,701 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:10:52,713 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-049.pkl
2017-02-05 23:10:54,897 INFO     epoch: 49 took 96.203s (0.002s in batching)
training loss:	0.529559
validation loss:	0.525607
validation error:	0.264800
2017-02-05 23:10:54,902 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:12:28,314 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-050.pkl
2017-02-05 23:12:30,504 INFO     epoch: 50 took 95.607s (0.001s in batching)
training loss:	0.528971
validation loss:	0.524735
validation error:	0.261400
2017-02-05 23:12:30,509 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:14:04,532 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-051.pkl
2017-02-05 23:14:06,700 INFO     epoch: 51 took 96.195s (0.001s in batching)
training loss:	0.528552
validation loss:	0.520244
validation error:	0.257800
2017-02-05 23:14:06,706 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:15:40,225 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-052.pkl
2017-02-05 23:15:42,361 INFO     epoch: 52 took 95.661s (0.001s in batching)
training loss:	0.527668
validation loss:	0.519291
validation error:	0.259500
2017-02-05 23:15:42,366 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:17:15,522 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-053.pkl
2017-02-05 23:17:17,666 INFO     epoch: 53 took 95.306s (0.001s in batching)
training loss:	0.527633
validation loss:	0.518827
validation error:	0.258700
2017-02-05 23:17:17,672 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:18:51,117 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-054.pkl
2017-02-05 23:18:53,329 INFO     epoch: 54 took 95.663s (0.001s in batching)
training loss:	0.526656
validation loss:	0.519627
validation error:	0.254700
2017-02-05 23:18:53,335 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:20:27,259 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-055.pkl
2017-02-05 23:20:29,425 INFO     epoch: 55 took 96.096s (0.001s in batching)
training loss:	0.526347
validation loss:	0.518567
validation error:	0.255500
2017-02-05 23:20:29,432 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:22:03,313 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-056.pkl
2017-02-05 23:22:05,469 INFO     epoch: 56 took 96.044s (0.001s in batching)
training loss:	0.525862
validation loss:	0.518935
validation error:	0.255900
2017-02-05 23:22:05,474 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:23:39,295 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-057.pkl
2017-02-05 23:23:41,436 INFO     epoch: 57 took 95.967s (0.001s in batching)
training loss:	0.525489
validation loss:	0.517017
validation error:	0.256700
2017-02-05 23:23:41,441 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:25:14,944 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-058.pkl
2017-02-05 23:25:17,150 INFO     epoch: 58 took 95.715s (0.001s in batching)
training loss:	0.525030
validation loss:	0.521453
validation error:	0.254300
2017-02-05 23:25:17,156 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:26:50,865 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-059.pkl
2017-02-05 23:26:53,042 INFO     epoch: 59 took 95.892s (0.001s in batching)
training loss:	0.524777
validation loss:	0.517482
validation error:	0.257400
2017-02-05 23:26:53,048 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:28:26,765 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-060.pkl
2017-02-05 23:28:28,971 INFO     epoch: 60 took 95.928s (0.001s in batching)
training loss:	0.524607
validation loss:	0.517484
validation error:	0.254000
2017-02-05 23:28:28,978 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:30:02,707 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-061.pkl
2017-02-05 23:30:04,873 INFO     epoch: 61 took 95.902s (0.001s in batching)
training loss:	0.523874
validation loss:	0.519019
validation error:	0.254300
2017-02-05 23:30:04,878 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:31:38,160 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-062.pkl
2017-02-05 23:31:40,348 INFO     epoch: 62 took 95.475s (0.001s in batching)
training loss:	0.523311
validation loss:	0.514963
validation error:	0.252200
2017-02-05 23:31:40,354 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:33:14,403 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-063.pkl
2017-02-05 23:33:16,620 INFO     epoch: 63 took 96.273s (0.001s in batching)
training loss:	0.522723
validation loss:	0.515766
validation error:	0.254700
2017-02-05 23:33:16,627 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:34:50,417 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-064.pkl
2017-02-05 23:34:52,597 INFO     epoch: 64 took 95.976s (0.001s in batching)
training loss:	0.522513
validation loss:	0.519817
validation error:	0.254300
2017-02-05 23:34:52,603 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:36:26,557 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-065.pkl
2017-02-05 23:36:28,731 INFO     epoch: 65 took 96.134s (0.001s in batching)
training loss:	0.522509
validation loss:	0.514026
validation error:	0.256500
2017-02-05 23:36:28,737 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:38:02,461 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-066.pkl
2017-02-05 23:38:04,652 INFO     epoch: 66 took 95.921s (0.001s in batching)
training loss:	0.521895
validation loss:	0.515529
validation error:	0.254000
2017-02-05 23:38:04,657 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:39:38,153 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-067.pkl
2017-02-05 23:39:40,309 INFO     epoch: 67 took 95.657s (0.001s in batching)
training loss:	0.521545
validation loss:	0.522786
validation error:	0.257000
2017-02-05 23:39:40,314 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:41:13,909 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-068.pkl
2017-02-05 23:41:16,070 INFO     epoch: 68 took 95.761s (0.001s in batching)
training loss:	0.520729
validation loss:	0.516780
validation error:	0.252000
2017-02-05 23:41:16,075 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:42:50,080 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-069.pkl
2017-02-05 23:42:52,256 INFO     epoch: 69 took 96.186s (0.001s in batching)
training loss:	0.520955
validation loss:	0.510794
validation error:	0.250700
2017-02-05 23:42:52,263 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:44:25,777 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-070.pkl
2017-02-05 23:44:27,899 INFO     epoch: 70 took 95.643s (0.001s in batching)
training loss:	0.520939
validation loss:	0.513851
validation error:	0.255700
2017-02-05 23:44:27,906 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:46:01,331 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-071.pkl
2017-02-05 23:46:03,546 INFO     epoch: 71 took 95.647s (0.001s in batching)
training loss:	0.519714
validation loss:	0.513283
validation error:	0.250400
2017-02-05 23:46:03,551 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:47:37,408 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-072.pkl
2017-02-05 23:47:39,593 INFO     epoch: 72 took 96.047s (0.001s in batching)
training loss:	0.520095
validation loss:	0.512645
validation error:	0.254400
2017-02-05 23:47:39,599 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:49:13,532 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-073.pkl
2017-02-05 23:49:15,696 INFO     epoch: 73 took 96.103s (0.001s in batching)
training loss:	0.519634
validation loss:	0.512593
validation error:	0.252500
2017-02-05 23:49:15,702 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:50:49,418 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-074.pkl
2017-02-05 23:50:51,594 INFO     epoch: 74 took 95.899s (0.001s in batching)
training loss:	0.519538
validation loss:	0.512662
validation error:	0.254000
2017-02-05 23:50:51,600 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:52:24,937 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-075.pkl
2017-02-05 23:52:27,122 INFO     epoch: 75 took 95.527s (0.001s in batching)
training loss:	0.519027
validation loss:	0.515789
validation error:	0.254200
2017-02-05 23:52:27,127 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:53:48,473 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-076.pkl
2017-02-05 23:53:50,351 INFO     epoch: 76 took 83.229s (0.001s in batching)
training loss:	0.518708
validation loss:	0.511922
validation error:	0.251800
2017-02-05 23:53:50,356 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:55:17,923 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-077.pkl
2017-02-05 23:55:20,043 INFO     epoch: 77 took 89.692s (0.001s in batching)
training loss:	0.518223
validation loss:	0.511843
validation error:	0.252900
2017-02-05 23:55:20,050 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:56:53,089 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-078.pkl
2017-02-05 23:56:55,237 INFO     epoch: 78 took 95.194s (0.001s in batching)
training loss:	0.518040
validation loss:	0.511770
validation error:	0.253600
2017-02-05 23:56:55,243 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-05 23:58:27,792 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-079.pkl
2017-02-05 23:58:29,929 INFO     epoch: 79 took 94.692s (0.001s in batching)
training loss:	0.517550
validation loss:	0.511721
validation error:	0.254900
2017-02-05 23:58:29,935 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:00:02,823 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-080.pkl
2017-02-06 00:00:04,952 INFO     epoch: 80 took 95.023s (0.001s in batching)
training loss:	0.517967
validation loss:	0.513808
validation error:	0.253400
2017-02-06 00:00:04,959 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:01:37,884 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-081.pkl
2017-02-06 00:01:40,017 INFO     epoch: 81 took 95.065s (0.001s in batching)
training loss:	0.517455
validation loss:	0.514098
validation error:	0.253400
2017-02-06 00:01:40,023 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:03:12,753 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-082.pkl
2017-02-06 00:03:14,912 INFO     epoch: 82 took 94.895s (0.001s in batching)
training loss:	0.517070
validation loss:	0.514963
validation error:	0.253900
2017-02-06 00:03:14,919 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:04:47,434 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-083.pkl
2017-02-06 00:04:49,563 INFO     epoch: 83 took 94.651s (0.001s in batching)
training loss:	0.516804
validation loss:	0.516659
validation error:	0.257800
2017-02-06 00:04:49,569 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:06:22,058 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-084.pkl
2017-02-06 00:06:24,197 INFO     epoch: 84 took 94.634s (0.001s in batching)
training loss:	0.517761
validation loss:	0.512949
validation error:	0.251700
2017-02-06 00:06:24,203 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:07:57,196 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-085.pkl
2017-02-06 00:07:59,372 INFO     epoch: 85 took 95.175s (0.001s in batching)
training loss:	0.516163
validation loss:	0.511287
validation error:	0.255300
2017-02-06 00:07:59,378 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:09:32,284 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-086.pkl
2017-02-06 00:09:34,437 INFO     epoch: 86 took 95.065s (0.001s in batching)
training loss:	0.516106
validation loss:	0.509063
validation error:	0.250600
2017-02-06 00:09:34,443 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:11:07,120 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-087.pkl
2017-02-06 00:11:09,262 INFO     epoch: 87 took 94.825s (0.001s in batching)
training loss:	0.515391
validation loss:	0.510924
validation error:	0.254000
2017-02-06 00:11:09,268 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:12:42,632 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-088.pkl
2017-02-06 00:12:44,804 INFO     epoch: 88 took 95.542s (0.001s in batching)
training loss:	0.516230
validation loss:	0.511026
validation error:	0.251700
2017-02-06 00:12:44,811 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:14:17,689 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-089.pkl
2017-02-06 00:14:19,846 INFO     epoch: 89 took 95.042s (0.001s in batching)
training loss:	0.515766
validation loss:	0.511948
validation error:	0.251200
2017-02-06 00:14:19,853 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:15:52,857 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-090.pkl
2017-02-06 00:15:55,014 INFO     epoch: 90 took 95.168s (0.001s in batching)
training loss:	0.515983
validation loss:	0.512150
validation error:	0.252400
2017-02-06 00:15:55,021 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:17:28,498 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-091.pkl
2017-02-06 00:17:30,659 INFO     epoch: 91 took 95.645s (0.001s in batching)
training loss:	0.515128
validation loss:	0.512714
validation error:	0.252200
2017-02-06 00:17:30,666 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:19:03,586 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-092.pkl
2017-02-06 00:19:05,756 INFO     epoch: 92 took 95.097s (0.002s in batching)
training loss:	0.515331
validation loss:	0.511123
validation error:	0.252900
2017-02-06 00:19:05,762 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:20:38,622 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-093.pkl
2017-02-06 00:20:40,770 INFO     epoch: 93 took 95.014s (0.001s in batching)
training loss:	0.515058
validation loss:	0.508248
validation error:	0.249700
2017-02-06 00:20:40,776 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:22:13,639 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-094.pkl
2017-02-06 00:22:15,812 INFO     epoch: 94 took 95.041s (0.001s in batching)
training loss:	0.514406
validation loss:	0.517998
validation error:	0.253800
2017-02-06 00:22:15,819 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:23:48,494 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-095.pkl
2017-02-06 00:23:50,626 INFO     epoch: 95 took 94.814s (0.001s in batching)
training loss:	0.513984
validation loss:	0.510522
validation error:	0.251500
2017-02-06 00:23:50,632 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:25:09,134 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-096.pkl
2017-02-06 00:25:10,961 INFO     epoch: 96 took 80.335s (0.001s in batching)
training loss:	0.514240
validation loss:	0.510962
validation error:	0.251900
2017-02-06 00:25:10,967 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:26:38,930 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-097.pkl
2017-02-06 00:26:41,132 INFO     epoch: 97 took 90.171s (0.001s in batching)
training loss:	0.513747
validation loss:	0.513306
validation error:	0.253700
2017-02-06 00:26:41,139 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:28:17,967 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-098.pkl
2017-02-06 00:28:20,192 INFO     epoch: 98 took 99.060s (0.001s in batching)
training loss:	0.514146
validation loss:	0.515094
validation error:	0.257500
2017-02-06 00:28:20,200 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
2017-02-06 00:29:56,555 INFO     Saving network params to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/epoch-099.pkl
2017-02-06 00:29:58,813 INFO     epoch: 99 took 98.621s (0.001s in batching)
training loss:	0.514136
validation loss:	0.511217
validation error:	0.252600
2017-02-06 00:29:58,823 INFO     Wrote output to trainNN/out/v049-finunified-3-ge1cb642:lstm-best-layers-50-20/config.json
