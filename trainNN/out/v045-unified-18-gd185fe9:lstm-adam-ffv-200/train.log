2017-01-26 23:53:56,175 DEBUG    version=v045-unified-18-gd185fe9:lstm-adam-ffv-200
2017-01-26 23:53:56,177 INFO     Open DBase(data/db/all240302-spk.dat, data/db/all240302-spk.idx, mode='r')
2017-01-26 23:54:10,340 DEBUG    getting all bc uttids...configs/lstm-adam-ffv/lstm-adam-ffv-200.json, train
2017-01-26 23:54:10,341 INFO     Open DBase(data/db/all240302-spk.dat, data/db/all240302-spk.idx, mode='r')
2017-01-26 23:54:34,198 DEBUG    loading cached extracted data from data/cache/extract-17095dffdd75068299ccb5dd895af8ecaa0fbe1575b09b5b1ad4e4febf4d84ae.pickle
2017-01-26 23:54:36,271 DEBUG    set input dim to 9
2017-01-26 23:54:36,272 DEBUG    input dim = 9
2017-01-26 23:54:36,531 DEBUG    shuffling batches
2017-01-26 23:56:53,992 DEBUG    shuffling done
2017-01-26 23:56:53,992 DEBUG    loading data into ram
2017-01-26 23:56:54,218 DEBUG    loading data took 0.226s (cpu: 0.129s)
2017-01-26 23:56:54,218 DEBUG    getting all bc uttids...configs/lstm-adam-ffv/lstm-adam-ffv-200.json, validate
2017-01-26 23:56:55,129 DEBUG    set input dim to 9
2017-01-26 23:56:55,129 DEBUG    input dim = 9
2017-01-26 23:56:55,564 DEBUG    shuffling batches
2017-01-26 23:57:08,764 DEBUG    shuffling done
2017-01-26 23:57:08,765 DEBUG    loading data into ram
2017-01-26 23:57:08,801 DEBUG    loading data took 0.037s (cpu: 0.013s)
2017-01-26 23:57:09,020 INFO     Training network with 169002 trainable out of 169402 total params.
2017-01-26 23:57:09,592 DEBUG    Using adam with learning_rate=0.001000
2017-01-26 23:57:43,658 DEBUG    Starting training...
2017-01-27 00:50:45,507 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-000.pkl
2017-01-27 00:51:25,721 INFO     epoch: 0 took 3222.062s (0.046s in batching)
training loss:	0.601484
validation loss:	0.587860
validation error:	0.313799
2017-01-27 00:51:25,724 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 01:32:48,391 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-001.pkl
2017-01-27 01:33:14,408 INFO     epoch: 1 took 2508.687s (0.043s in batching)
training loss:	0.556787
validation loss:	0.600122
validation error:	0.317408
2017-01-27 01:33:14,411 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 02:06:35,567 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-002.pkl
2017-01-27 02:07:01,739 INFO     epoch: 2 took 2027.331s (0.042s in batching)
training loss:	0.511638
validation loss:	0.634927
validation error:	0.324575
2017-01-27 02:07:01,742 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 02:40:16,809 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-003.pkl
2017-01-27 02:40:42,919 INFO     epoch: 3 took 2021.179s (0.047s in batching)
training loss:	0.458537
validation loss:	0.680630
validation error:	0.329497
2017-01-27 02:40:42,922 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 03:13:58,323 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-004.pkl
2017-01-27 03:14:24,353 INFO     epoch: 4 took 2021.434s (0.042s in batching)
training loss:	0.408868
validation loss:	0.764649
validation error:	0.341745
2017-01-27 03:14:24,453 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 03:47:37,927 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-005.pkl
2017-01-27 03:48:03,963 INFO     epoch: 5 took 2019.611s (0.044s in batching)
training loss:	0.367457
validation loss:	0.842559
validation error:	0.349418
2017-01-27 03:48:03,967 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 04:21:20,482 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-006.pkl
2017-01-27 04:21:46,434 INFO     epoch: 6 took 2022.471s (0.046s in batching)
training loss:	0.333250
validation loss:	0.906188
validation error:	0.348957
2017-01-27 04:21:46,437 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 04:55:02,546 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-007.pkl
2017-01-27 04:55:28,677 INFO     epoch: 7 took 2022.244s (0.043s in batching)
training loss:	0.304366
validation loss:	0.966117
validation error:	0.352268
2017-01-27 04:55:28,681 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 05:28:45,009 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-008.pkl
2017-01-27 05:29:11,083 INFO     epoch: 8 took 2022.405s (0.046s in batching)
training loss:	0.280780
validation loss:	1.062724
validation error:	0.359197
2017-01-27 05:29:11,086 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 06:02:22,969 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-009.pkl
2017-01-27 06:02:48,995 INFO     epoch: 9 took 2017.912s (0.042s in batching)
training loss:	0.261562
validation loss:	1.062980
validation error:	0.354235
2017-01-27 06:02:48,998 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 06:36:03,480 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-010.pkl
2017-01-27 06:36:29,386 INFO     epoch: 10 took 2020.391s (0.048s in batching)
training loss:	0.245245
validation loss:	1.144694
validation error:	0.357437
2017-01-27 06:36:29,391 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 07:09:43,479 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-011.pkl
2017-01-27 07:10:09,412 INFO     epoch: 11 took 2020.026s (0.044s in batching)
training loss:	0.231474
validation loss:	1.127436
validation error:	0.357784
2017-01-27 07:10:09,415 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 07:43:24,512 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-012.pkl
2017-01-27 07:43:50,518 INFO     epoch: 12 took 2021.106s (0.042s in batching)
training loss:	0.219595
validation loss:	1.193591
validation error:	0.359088
2017-01-27 07:43:50,522 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 08:17:03,957 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-013.pkl
2017-01-27 08:17:29,929 INFO     epoch: 13 took 2019.411s (0.046s in batching)
training loss:	0.209454
validation loss:	1.198501
validation error:	0.355390
2017-01-27 08:17:29,932 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 08:50:43,876 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-014.pkl
2017-01-27 08:51:09,633 INFO     epoch: 14 took 2019.704s (0.041s in batching)
training loss:	0.200959
validation loss:	1.251095
validation error:	0.361903
2017-01-27 08:51:09,637 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 09:24:22,363 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-015.pkl
2017-01-27 09:24:48,431 INFO     epoch: 15 took 2018.798s (0.045s in batching)
training loss:	0.193839
validation loss:	1.307402
validation error:	0.361264
2017-01-27 09:24:48,434 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 09:58:02,706 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/epoch-016.pkl
2017-01-27 09:58:28,671 INFO     epoch: 16 took 2020.240s (0.044s in batching)
training loss:	0.187377
validation loss:	1.294519
validation error:	0.360149
2017-01-27 09:58:28,675 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-200/config.json
2017-01-27 10:01:47,925 INFO     received exit signal, waiting for epoch to finish...
