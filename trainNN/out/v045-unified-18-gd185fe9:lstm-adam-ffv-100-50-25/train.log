2017-01-26 23:51:33,656 DEBUG    version=v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25
2017-01-26 23:51:33,658 INFO     Open DBase(data/db/all240302-spk.dat, data/db/all240302-spk.idx, mode='r')
2017-01-26 23:51:49,092 DEBUG    getting all bc uttids...configs/lstm-adam-ffv/lstm-adam-ffv-100-50-25.json, train
2017-01-26 23:51:49,093 INFO     Open DBase(data/db/all240302-spk.dat, data/db/all240302-spk.idx, mode='r')
2017-01-26 23:52:15,125 DEBUG    loading cached extracted data from data/cache/extract-17095dffdd75068299ccb5dd895af8ecaa0fbe1575b09b5b1ad4e4febf4d84ae.pickle
2017-01-26 23:52:17,281 DEBUG    set input dim to 9
2017-01-26 23:52:17,281 DEBUG    input dim = 9
2017-01-26 23:52:17,566 DEBUG    shuffling batches
2017-01-26 23:53:55,210 DEBUG    shuffling done
2017-01-26 23:53:55,210 DEBUG    loading data into ram
2017-01-26 23:53:55,340 DEBUG    loading data took 0.130s (cpu: 0.130s)
2017-01-26 23:53:55,341 DEBUG    getting all bc uttids...configs/lstm-adam-ffv/lstm-adam-ffv-100-50-25.json, validate
2017-01-26 23:53:55,909 DEBUG    set input dim to 9
2017-01-26 23:53:55,909 DEBUG    input dim = 9
2017-01-26 23:53:56,201 DEBUG    shuffling batches
2017-01-26 23:54:04,216 DEBUG    shuffling done
2017-01-26 23:54:04,217 DEBUG    loading data into ram
2017-01-26 23:54:04,230 DEBUG    loading data took 0.013s (cpu: 0.013s)
2017-01-26 23:54:04,599 INFO     Training network with 82377 trainable out of 82727 total params.
2017-01-26 23:54:06,626 DEBUG    Using adam with learning_rate=0.001000
2017-01-26 23:55:10,031 DEBUG    Starting training...
2017-01-27 00:49:53,114 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-000.pkl
2017-01-27 00:51:02,209 INFO     epoch: 0 took 3352.177s (0.047s in batching)
training loss:	0.600681
validation loss:	0.580405
validation error:	0.306245
2017-01-27 00:51:02,213 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 01:34:42,507 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-001.pkl
2017-01-27 01:35:26,460 INFO     epoch: 1 took 2664.251s (0.049s in batching)
training loss:	0.560696
validation loss:	0.574324
validation error:	0.299836
2017-01-27 01:35:26,463 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 02:11:57,653 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-002.pkl
2017-01-27 02:12:41,481 INFO     epoch: 2 took 2235.021s (0.050s in batching)
training loss:	0.531642
validation loss:	0.590331
validation error:	0.303703
2017-01-27 02:12:41,484 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 02:49:14,147 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-003.pkl
2017-01-27 02:49:58,010 INFO     epoch: 3 took 2236.529s (0.049s in batching)
training loss:	0.499933
validation loss:	0.619792
validation error:	0.313338
2017-01-27 02:49:58,013 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 03:26:31,671 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-004.pkl
2017-01-27 03:27:15,580 INFO     epoch: 4 took 2237.570s (0.050s in batching)
training loss:	0.468944
validation loss:	0.665347
validation error:	0.323648
2017-01-27 03:27:15,583 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 04:03:53,024 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-005.pkl
2017-01-27 04:04:36,928 INFO     epoch: 5 took 2241.348s (0.050s in batching)
training loss:	0.440559
validation loss:	0.691127
validation error:	0.326166
2017-01-27 04:04:36,931 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 04:41:09,118 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-006.pkl
2017-01-27 04:41:53,012 INFO     epoch: 6 took 2236.083s (0.049s in batching)
training loss:	0.415908
validation loss:	0.723521
validation error:	0.327841
2017-01-27 04:41:53,015 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 05:18:27,124 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-007.pkl
2017-01-27 05:19:11,016 INFO     epoch: 7 took 2238.004s (0.049s in batching)
training loss:	0.394254
validation loss:	0.771748
validation error:	0.334533
2017-01-27 05:19:11,019 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 05:55:47,434 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-008.pkl
2017-01-27 05:56:31,087 INFO     epoch: 8 took 2240.071s (0.051s in batching)
training loss:	0.375692
validation loss:	0.795973
validation error:	0.336853
2017-01-27 05:56:31,090 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 06:33:04,670 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-009.pkl
2017-01-27 06:33:48,595 INFO     epoch: 9 took 2237.509s (0.051s in batching)
training loss:	0.359074
validation loss:	0.816809
validation error:	0.337393
2017-01-27 06:33:48,598 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 07:10:20,462 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-010.pkl
2017-01-27 07:11:04,381 INFO     epoch: 10 took 2235.785s (0.049s in batching)
training loss:	0.345009
validation loss:	0.850979
validation error:	0.343450
2017-01-27 07:11:04,384 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 07:47:40,697 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-011.pkl
2017-01-27 07:48:24,547 INFO     epoch: 11 took 2240.167s (0.049s in batching)
training loss:	0.332115
validation loss:	0.855812
validation error:	0.341586
2017-01-27 07:48:24,551 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 08:25:00,689 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-012.pkl
2017-01-27 08:25:44,585 INFO     epoch: 12 took 2240.038s (0.057s in batching)
training loss:	0.321220
validation loss:	0.920930
validation error:	0.344724
2017-01-27 08:25:44,589 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 09:02:18,977 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-013.pkl
2017-01-27 09:03:02,872 INFO     epoch: 13 took 2238.286s (0.051s in batching)
training loss:	0.311729
validation loss:	0.898061
validation error:	0.346032
2017-01-27 09:03:02,875 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 09:39:39,260 INFO     Saving network params to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/epoch-014.pkl
2017-01-27 09:40:23,085 INFO     epoch: 14 took 2240.213s (0.056s in batching)
training loss:	0.303007
validation loss:	0.936472
validation error:	0.349145
2017-01-27 09:40:23,089 INFO     Wrote output to trainNN/out/v045-unified-18-gd185fe9:lstm-adam-ffv-100-50-25/config.json
2017-01-27 10:01:47,862 INFO     received exit signal, waiting for epoch to finish...
