2016-12-08 01:35:51 >>> version=v026-sgd-1
2016-12-08 01:35:51 >>> loading config file extract_pfiles_python/out/v024-gauss-sgd-1-7-g13ff9f6-context40/config.json
2016-12-08 01:35:51 >>> loading numpy file extract_pfiles_python/out/v024-gauss-sgd-1-7-g13ff9f6-context40/train.npz
2016-12-08 01:35:54 >>> loading numpy file extract_pfiles_python/out/v024-gauss-sgd-1-7-g13ff9f6-context40/validate.npz
2016-12-08 01:35:55 >>> Training network with 21452 trainable out of 21452 total params.
2016-12-08 01:35:55 >>> Using sgd with learning_rate=1.000000
2016-12-08 01:35:55 >>> Compiling theano functions...
2016-12-08 01:35:55 >>> Starting training...
2016-12-08 01:36:22 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-000.pkl
2016-12-08 01:36:24 >>> epoch: 0 took 28.644s
training loss:	0.595742
validation loss:	0.578276
validation error:	0.299495
2016-12-08 01:36:50 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-001.pkl
2016-12-08 01:36:52 >>> epoch: 1 took 28.479s
training loss:	0.579789
validation loss:	0.567886
validation error:	0.288774
2016-12-08 01:37:19 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-002.pkl
2016-12-08 01:37:20 >>> epoch: 2 took 28.360s
training loss:	0.573622
validation loss:	0.563636
validation error:	0.284972
2016-12-08 01:37:47 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-003.pkl
2016-12-08 01:37:49 >>> epoch: 3 took 28.802s
training loss:	0.570419
validation loss:	0.561478
validation error:	0.283028
2016-12-08 01:38:16 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-004.pkl
2016-12-08 01:38:18 >>> epoch: 4 took 28.475s
training loss:	0.567884
validation loss:	0.558715
validation error:	0.280693
2016-12-08 01:38:56 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-005.pkl
2016-12-08 01:38:59 >>> epoch: 5 took 41.350s
training loss:	0.565594
validation loss:	0.558748
validation error:	0.280734
2016-12-08 01:39:46 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-006.pkl
2016-12-08 01:39:49 >>> epoch: 6 took 50.381s
training loss:	0.563742
validation loss:	0.561201
validation error:	0.283335
2016-12-08 01:40:36 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-007.pkl
2016-12-08 01:40:39 >>> epoch: 7 took 49.672s
training loss:	0.562196
validation loss:	0.555662
validation error:	0.280290
2016-12-08 01:41:26 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-008.pkl
2016-12-08 01:41:29 >>> epoch: 8 took 49.444s
training loss:	0.560710
validation loss:	0.553450
validation error:	0.277865
2016-12-08 01:42:15 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-009.pkl
2016-12-08 01:42:18 >>> epoch: 9 took 49.813s
training loss:	0.559511
validation loss:	0.551510
validation error:	0.276960
2016-12-08 01:43:05 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-010.pkl
2016-12-08 01:43:08 >>> epoch: 10 took 49.531s
training loss:	0.558491
validation loss:	0.553242
validation error:	0.277744
2016-12-08 01:43:55 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-011.pkl
2016-12-08 01:43:58 >>> epoch: 11 took 49.834s
training loss:	0.557697
validation loss:	0.551734
validation error:	0.276455
2016-12-08 01:44:45 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-012.pkl
2016-12-08 01:44:49 >>> epoch: 12 took 50.841s
training loss:	0.556748
validation loss:	0.551185
validation error:	0.275816
2016-12-08 01:45:36 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-013.pkl
2016-12-08 01:45:39 >>> epoch: 13 took 50.669s
training loss:	0.556105
validation loss:	0.554098
validation error:	0.277618
2016-12-08 01:46:26 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-014.pkl
2016-12-08 01:46:29 >>> epoch: 14 took 49.659s
training loss:	0.555427
validation loss:	0.551334
validation error:	0.276101
2016-12-08 01:47:16 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-015.pkl
2016-12-08 01:47:19 >>> epoch: 15 took 49.889s
training loss:	0.554775
validation loss:	0.550882
validation error:	0.275541
2016-12-08 01:48:05 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-016.pkl
2016-12-08 01:48:08 >>> epoch: 16 took 49.586s
training loss:	0.554262
validation loss:	0.551067
validation error:	0.276345
2016-12-08 01:48:55 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-017.pkl
2016-12-08 01:48:58 >>> epoch: 17 took 49.465s
training loss:	0.553581
validation loss:	0.548541
validation error:	0.274738
2016-12-08 01:49:44 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-018.pkl
2016-12-08 01:49:47 >>> epoch: 18 took 49.522s
training loss:	0.553094
validation loss:	0.550517
validation error:	0.275805
2016-12-08 01:50:34 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-019.pkl
2016-12-08 01:50:37 >>> epoch: 19 took 49.649s
training loss:	0.552627
validation loss:	0.552564
validation error:	0.276979
2016-12-08 01:51:24 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-020.pkl
2016-12-08 01:51:27 >>> epoch: 20 took 49.880s
training loss:	0.552148
validation loss:	0.549717
validation error:	0.275547
2016-12-08 01:52:13 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-021.pkl
2016-12-08 01:52:17 >>> epoch: 21 took 49.677s
training loss:	0.551707
validation loss:	0.548385
validation error:	0.274738
2016-12-08 01:53:03 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-022.pkl
2016-12-08 01:53:06 >>> epoch: 22 took 49.671s
training loss:	0.551409
validation loss:	0.548001
validation error:	0.274644
2016-12-08 01:53:53 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-023.pkl
2016-12-08 01:53:56 >>> epoch: 23 took 49.818s
training loss:	0.551037
validation loss:	0.548063
validation error:	0.274872
2016-12-08 01:54:43 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-024.pkl
2016-12-08 01:54:46 >>> epoch: 24 took 49.876s
training loss:	0.550608
validation loss:	0.550565
validation error:	0.275023
2016-12-08 01:55:32 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-025.pkl
2016-12-08 01:55:36 >>> epoch: 25 took 49.621s
training loss:	0.550219
validation loss:	0.548780
validation error:	0.274795
2016-12-08 01:56:22 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-026.pkl
2016-12-08 01:56:25 >>> epoch: 26 took 49.552s
training loss:	0.549821
validation loss:	0.553120
validation error:	0.278337
2016-12-08 01:57:11 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-027.pkl
2016-12-08 01:57:14 >>> epoch: 27 took 49.304s
training loss:	0.549424
validation loss:	0.547517
validation error:	0.273651
2016-12-08 01:58:01 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-028.pkl
2016-12-08 01:58:04 >>> epoch: 28 took 49.849s
training loss:	0.548988
validation loss:	0.547030
validation error:	0.274258
2016-12-08 01:58:51 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-029.pkl
2016-12-08 01:58:54 >>> epoch: 29 took 49.646s
training loss:	0.548737
validation loss:	0.547403
validation error:	0.274518
2016-12-08 01:59:40 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-030.pkl
2016-12-08 01:59:43 >>> epoch: 30 took 49.474s
training loss:	0.548397
validation loss:	0.545638
validation error:	0.272680
2016-12-08 02:00:30 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-031.pkl
2016-12-08 02:00:33 >>> epoch: 31 took 49.437s
training loss:	0.548008
validation loss:	0.545419
validation error:	0.273429
2016-12-08 02:01:19 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-032.pkl
2016-12-08 02:01:23 >>> epoch: 32 took 49.750s
training loss:	0.547711
validation loss:	0.550075
validation error:	0.276299
2016-12-08 02:02:09 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-033.pkl
2016-12-08 02:02:12 >>> epoch: 33 took 49.344s
training loss:	0.547459
validation loss:	0.545655
validation error:	0.273547
2016-12-08 02:02:58 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-034.pkl
2016-12-08 02:03:02 >>> epoch: 34 took 49.535s
training loss:	0.547189
validation loss:	0.568746
validation error:	0.287537
2016-12-08 02:03:48 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-035.pkl
2016-12-08 02:03:51 >>> epoch: 35 took 49.354s
training loss:	0.546827
validation loss:	0.545045
validation error:	0.272513
2016-12-08 02:04:37 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-036.pkl
2016-12-08 02:04:40 >>> epoch: 36 took 49.598s
training loss:	0.546607
validation loss:	0.547398
validation error:	0.273193
2016-12-08 02:05:27 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-037.pkl
2016-12-08 02:05:30 >>> epoch: 37 took 49.588s
training loss:	0.546347
validation loss:	0.546819
validation error:	0.275012
2016-12-08 02:06:16 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-038.pkl
2016-12-08 02:06:19 >>> epoch: 38 took 49.313s
training loss:	0.546056
validation loss:	0.545533
validation error:	0.272691
2016-12-08 02:07:06 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-039.pkl
2016-12-08 02:07:09 >>> epoch: 39 took 49.502s
training loss:	0.545804
validation loss:	0.546584
validation error:	0.273372
2016-12-08 02:07:55 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-040.pkl
2016-12-08 02:07:58 >>> epoch: 40 took 49.621s
training loss:	0.545578
validation loss:	0.545420
validation error:	0.273073
2016-12-08 02:08:45 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-041.pkl
2016-12-08 02:08:48 >>> epoch: 41 took 49.387s
training loss:	0.545375
validation loss:	0.545828
validation error:	0.272527
2016-12-08 02:09:34 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-042.pkl
2016-12-08 02:09:37 >>> epoch: 42 took 49.509s
training loss:	0.545187
validation loss:	0.545063
validation error:	0.272176
2016-12-08 02:10:24 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-043.pkl
2016-12-08 02:10:27 >>> epoch: 43 took 49.569s
training loss:	0.544913
validation loss:	0.546266
validation error:	0.273207
2016-12-08 02:11:13 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-044.pkl
2016-12-08 02:11:17 >>> epoch: 44 took 49.567s
training loss:	0.544705
validation loss:	0.544147
validation error:	0.272063
2016-12-08 02:12:03 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-045.pkl
2016-12-08 02:12:06 >>> epoch: 45 took 49.544s
training loss:	0.544517
validation loss:	0.544359
validation error:	0.271792
2016-12-08 02:12:52 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-046.pkl
2016-12-08 02:12:56 >>> epoch: 46 took 49.457s
training loss:	0.544361
validation loss:	0.554389
validation error:	0.278787
2016-12-08 02:13:42 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-047.pkl
2016-12-08 02:13:45 >>> epoch: 47 took 49.465s
training loss:	0.544090
validation loss:	0.544055
validation error:	0.272483
2016-12-08 02:14:31 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-048.pkl
2016-12-08 02:14:35 >>> epoch: 48 took 49.584s
training loss:	0.543914
validation loss:	0.543956
validation error:	0.271457
2016-12-08 02:15:21 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-049.pkl
2016-12-08 02:15:24 >>> epoch: 49 took 49.465s
training loss:	0.543836
validation loss:	0.550765
validation error:	0.276414
2016-12-08 02:16:10 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-050.pkl
2016-12-08 02:16:14 >>> epoch: 50 took 49.512s
training loss:	0.543615
validation loss:	0.545937
validation error:	0.273075
2016-12-08 02:17:00 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-051.pkl
2016-12-08 02:17:03 >>> epoch: 51 took 49.503s
training loss:	0.543550
validation loss:	0.544375
validation error:	0.271495
2016-12-08 02:17:49 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-052.pkl
2016-12-08 02:17:52 >>> epoch: 52 took 49.284s
training loss:	0.543314
validation loss:	0.544136
validation error:	0.272359
2016-12-08 02:18:38 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-053.pkl
2016-12-08 02:18:42 >>> epoch: 53 took 49.371s
training loss:	0.543167
validation loss:	0.549034
validation error:	0.274112
2016-12-08 02:19:28 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-054.pkl
2016-12-08 02:19:31 >>> epoch: 54 took 49.263s
training loss:	0.543059
validation loss:	0.544039
validation error:	0.272425
2016-12-08 02:20:17 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-055.pkl
2016-12-08 02:20:20 >>> epoch: 55 took 49.384s
training loss:	0.542850
validation loss:	0.544555
validation error:	0.272576
2016-12-08 02:21:07 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-056.pkl
2016-12-08 02:21:10 >>> epoch: 56 took 49.408s
training loss:	0.542665
validation loss:	0.544692
validation error:	0.272502
2016-12-08 02:21:56 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-057.pkl
2016-12-08 02:21:59 >>> epoch: 57 took 49.151s
training loss:	0.542574
validation loss:	0.544382
validation error:	0.273281
2016-12-08 02:22:45 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-058.pkl
2016-12-08 02:22:49 >>> epoch: 58 took 49.600s
training loss:	0.542402
validation loss:	0.544074
validation error:	0.272055
2016-12-08 02:23:35 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-059.pkl
2016-12-08 02:23:38 >>> epoch: 59 took 49.663s
training loss:	0.542334
validation loss:	0.545885
validation error:	0.273542
2016-12-08 02:24:24 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-060.pkl
2016-12-08 02:24:28 >>> epoch: 60 took 49.350s
training loss:	0.542215
validation loss:	0.544906
validation error:	0.272595
2016-12-08 02:25:14 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-061.pkl
2016-12-08 02:25:17 >>> epoch: 61 took 49.283s
training loss:	0.542049
validation loss:	0.545374
validation error:	0.272505
2016-12-08 02:26:03 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-062.pkl
2016-12-08 02:26:06 >>> epoch: 62 took 49.613s
training loss:	0.541878
validation loss:	0.544535
validation error:	0.272839
2016-12-08 02:26:52 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-063.pkl
2016-12-08 02:26:56 >>> epoch: 63 took 49.158s
training loss:	0.541819
validation loss:	0.543691
validation error:	0.271690
2016-12-08 02:27:42 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-064.pkl
2016-12-08 02:27:45 >>> epoch: 64 took 49.281s
training loss:	0.541665
validation loss:	0.546461
validation error:	0.274027
2016-12-08 02:28:31 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-065.pkl
2016-12-08 02:28:34 >>> epoch: 65 took 49.057s
training loss:	0.541586
validation loss:	0.543464
validation error:	0.271169
2016-12-08 02:29:20 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-066.pkl
2016-12-08 02:29:23 >>> epoch: 66 took 49.468s
training loss:	0.541450
validation loss:	0.543476
validation error:	0.272060
2016-12-08 02:30:09 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-067.pkl
2016-12-08 02:30:13 >>> epoch: 67 took 49.267s
training loss:	0.541307
validation loss:	0.543641
validation error:	0.271794
2016-12-08 02:30:59 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-068.pkl
2016-12-08 02:31:02 >>> epoch: 68 took 49.299s
training loss:	0.541174
validation loss:	0.543901
validation error:	0.271575
2016-12-08 02:31:48 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-069.pkl
2016-12-08 02:31:51 >>> epoch: 69 took 49.307s
training loss:	0.541122
validation loss:	0.543525
validation error:	0.270960
2016-12-08 02:32:38 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-070.pkl
2016-12-08 02:32:41 >>> epoch: 70 took 49.730s
training loss:	0.540959
validation loss:	0.546339
validation error:	0.273791
2016-12-08 02:33:27 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-071.pkl
2016-12-08 02:33:30 >>> epoch: 71 took 49.275s
training loss:	0.540824
validation loss:	0.545256
validation error:	0.271844
2016-12-08 02:34:16 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-072.pkl
2016-12-08 02:34:19 >>> epoch: 72 took 49.084s
training loss:	0.540716
validation loss:	0.546019
validation error:	0.273374
2016-12-08 02:35:06 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-073.pkl
2016-12-08 02:35:09 >>> epoch: 73 took 49.377s
training loss:	0.540669
validation loss:	0.544083
validation error:	0.271578
2016-12-08 02:35:55 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-074.pkl
2016-12-08 02:35:58 >>> epoch: 74 took 49.339s
training loss:	0.540517
validation loss:	0.542960
validation error:	0.270631
2016-12-08 02:36:44 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-075.pkl
2016-12-08 02:36:48 >>> epoch: 75 took 49.493s
training loss:	0.540418
validation loss:	0.543919
validation error:	0.272519
2016-12-08 02:37:34 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-076.pkl
2016-12-08 02:37:37 >>> epoch: 76 took 49.169s
training loss:	0.540282
validation loss:	0.545140
validation error:	0.272362
2016-12-08 02:38:23 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-077.pkl
2016-12-08 02:38:26 >>> epoch: 77 took 49.198s
training loss:	0.540171
validation loss:	0.544223
validation error:	0.271490
2016-12-08 02:39:12 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-078.pkl
2016-12-08 02:39:16 >>> epoch: 78 took 49.615s
training loss:	0.540044
validation loss:	0.543267
validation error:	0.271248
2016-12-08 02:40:02 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-079.pkl
2016-12-08 02:40:05 >>> epoch: 79 took 49.400s
training loss:	0.539918
validation loss:	0.542949
validation error:	0.271646
2016-12-08 02:40:51 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-080.pkl
2016-12-08 02:40:54 >>> epoch: 80 took 49.178s
training loss:	0.539794
validation loss:	0.544943
validation error:	0.272461
2016-12-08 02:41:41 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-081.pkl
2016-12-08 02:41:44 >>> epoch: 81 took 49.688s
training loss:	0.539703
validation loss:	0.544605
validation error:	0.272505
2016-12-08 02:42:30 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-082.pkl
2016-12-08 02:42:33 >>> epoch: 82 took 49.249s
training loss:	0.539520
validation loss:	0.543258
validation error:	0.271723
2016-12-08 02:43:19 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-083.pkl
2016-12-08 02:43:22 >>> epoch: 83 took 49.312s
training loss:	0.539441
validation loss:	0.543588
validation error:	0.272044
2016-12-08 02:44:09 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-084.pkl
2016-12-08 02:44:12 >>> epoch: 84 took 49.576s
training loss:	0.539293
validation loss:	0.543375
validation error:	0.271454
2016-12-08 02:44:58 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-085.pkl
2016-12-08 02:45:01 >>> epoch: 85 took 49.299s
training loss:	0.539243
validation loss:	0.545722
validation error:	0.272944
2016-12-08 02:45:48 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-086.pkl
2016-12-08 02:45:51 >>> epoch: 86 took 49.515s
training loss:	0.539137
validation loss:	0.541964
validation error:	0.270796
2016-12-08 02:46:37 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-087.pkl
2016-12-08 02:46:40 >>> epoch: 87 took 49.389s
training loss:	0.539038
validation loss:	0.542170
validation error:	0.271465
2016-12-08 02:47:26 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-088.pkl
2016-12-08 02:47:29 >>> epoch: 88 took 49.223s
training loss:	0.538908
validation loss:	0.541885
validation error:	0.270620
2016-12-08 02:48:16 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-089.pkl
2016-12-08 02:48:19 >>> epoch: 89 took 49.676s
training loss:	0.538811
validation loss:	0.544660
validation error:	0.272554
2016-12-08 02:49:05 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-090.pkl
2016-12-08 02:49:08 >>> epoch: 90 took 49.291s
training loss:	0.538789
validation loss:	0.542529
validation error:	0.270140
2016-12-08 02:49:54 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-091.pkl
2016-12-08 02:49:58 >>> epoch: 91 took 49.212s
training loss:	0.538686
validation loss:	0.546091
validation error:	0.274121
2016-12-08 02:50:44 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-092.pkl
2016-12-08 02:50:47 >>> epoch: 92 took 49.550s
training loss:	0.538595
validation loss:	0.541899
validation error:	0.270450
2016-12-08 02:51:33 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-093.pkl
2016-12-08 02:51:36 >>> epoch: 93 took 49.360s
training loss:	0.538462
validation loss:	0.548599
validation error:	0.275207
2016-12-08 02:52:23 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-094.pkl
2016-12-08 02:52:26 >>> epoch: 94 took 49.290s
training loss:	0.538399
validation loss:	0.543326
validation error:	0.271158
2016-12-08 02:53:12 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-095.pkl
2016-12-08 02:53:15 >>> epoch: 95 took 49.268s
training loss:	0.538284
validation loss:	0.543235
validation error:	0.272156
2016-12-08 02:54:01 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-096.pkl
2016-12-08 02:54:04 >>> epoch: 96 took 49.206s
training loss:	0.538203
validation loss:	0.542592
validation error:	0.271095
2016-12-08 02:54:51 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-097.pkl
2016-12-08 02:54:54 >>> epoch: 97 took 49.624s
training loss:	0.538146
validation loss:	0.542258
validation error:	0.270436
2016-12-08 02:55:40 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-098.pkl
2016-12-08 02:55:43 >>> epoch: 98 took 49.248s
training loss:	0.538030
validation loss:	0.542631
validation error:	0.271846
2016-12-08 02:56:29 >>> Saving network params to trainNN/out/v026-sgd-1/epoch-099.pkl
2016-12-08 02:56:32 >>> epoch: 99 took 49.288s
training loss:	0.538098
validation loss:	0.544310
validation error:	0.271161
2016-12-08 02:56:32 >>> Wrote output to trainNN/out/v026-sgd-1/config.json
